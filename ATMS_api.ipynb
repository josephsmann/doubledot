{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# doubledot.ATMS\n",
    "\n",
    ">  Definition of the ATMS_api class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp ATMS_api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "from nbdev.showdoc import *\n",
    "import requests\n",
    "import json\n",
    "import jmespath as jp\n",
    "import re\n",
    "from time import sleep\n",
    "from fastcore.basics import patch\n",
    "import fileinput\n",
    "import pandas as pd\n",
    "import os\n",
    "from fastcore.test import test_eq\n",
    "import glob\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class ATMS_api:\n",
    "    class_download_dir = os.path.join(os.getcwd(),'atms_download')\n",
    "\n",
    "    def __init__(self):\n",
    "        self.telus_access_token = ATMS_api.get_atms_authentication()\n",
    "        self.obj_d = {}\n",
    "\n",
    "        # create unique download directory per instance\n",
    "        if not os.path.exists(ATMS_api.class_download_dir):\n",
    "            os.makedirs(ATMS_api.class_download_dir)\n",
    "            print(f\"Directory 'atms_download' created successfully.\")\n",
    "        else:\n",
    "            print(f\"Directory 'atms_download' already exists.\")\n",
    "\n",
    "        # generate a unique directory name with a random string\n",
    "        random_string = ''.join(random.choices('abcdefghijklmnopqrstuvwxyz0123456789', k=8))\n",
    "        self.download_dir  = os.path.join(ATMS_api.class_download_dir, random_string)\n",
    "\n",
    "        # Check if the new director already exists in the directory\n",
    "        while os.path.exists(self.download_dir):\n",
    "            # If the directory name already exists, generate a new one\n",
    "            random_string  = ''.join(random.choices('abcdefghijklmnopqrstuvwxyz0123456789', k=8))\n",
    "            self.download_dir  = os.path.join(ATMS_api.class_download_dir, random_string)\n",
    "        \n",
    "        os.mkdir(self.download_dir)\n",
    "        self.id = random_string\n",
    "        print(\"my id is\", self.id)\n",
    "        \n",
    "    def list_files(self):\n",
    "        \"\"\" returns list of files in download folder \"\"\"\n",
    "        print('id is:', self.id)\n",
    "        if os.path.exists(self.download_dir):\n",
    "            return os.listdir(self.download_dir)\n",
    "        else:\n",
    "            return []\n",
    "\n",
    "    @staticmethod\n",
    "    def delete_all_data():\n",
    "        \"\"\" delete all the subdirectories and files in the download directory \"\"\"\n",
    "        for dir_path in glob.glob(os.path.join(ATMS_api.class_download_dir, \"*\")):\n",
    "            if os.path.isdir(dir_path):\n",
    "                for file_path in glob.glob(os.path.join(dir_path, \"*\")):\n",
    "                    if os.path.isfile(file_path):\n",
    "                        os.remove(file_path)\n",
    "                        print(f\"File '{file_path}' deleted successfully.\")\n",
    "                os.removedirs(dir_path) \n",
    "                print(f\"Directory '{dir_path}' deleted successfully.\")  \n",
    "        print(f\"Directory '{ATMS_api.class_download_dir}' deleted successfully.\")   \n",
    "\n",
    "    \n",
    "    def clean_data_dir(self,\n",
    "                       obj_s: str = None):\n",
    "        glob_s = os.path.join(self.download_dir, f\"*{obj_s if obj_s else ''}*.json\")\n",
    "        file_l = glob.glob(glob_s)\n",
    "        # print(file_l)\n",
    "        for file_path in file_l:\n",
    "            if os.path.isfile(file_path):\n",
    "                os.remove(file_path)\n",
    "                print(f\"File '{file_path}' deleted successfully.\")\n",
    "\n",
    "\n",
    "    @staticmethod    \n",
    "    def get_atms_authentication():\n",
    "        \"\"\"get access token for ATMS API\n",
    "\n",
    "        Returns:\n",
    "            response object: response object from the API call \n",
    "        \"\"\"\n",
    "        vantix_url = \"http://crm-api-telus.atmsplus.com/auth\"\n",
    "        \n",
    "        with open('secrets.json') as f:\n",
    "            secrets = json.load(f)\n",
    "\n",
    "        payload = json.dumps({\n",
    "            \"username\": secrets['vantix_user'],\n",
    "            \"password\": secrets['vantix_pw'],\n",
    "            \"rememberMe\": True\n",
    "        })\n",
    "        headers = {\n",
    "            'Content-Type': 'application/json'\n",
    "        }\n",
    "\n",
    "        response = requests.request(\"POST\", vantix_url, headers=headers, data=payload)\n",
    "        assert response.status_code == 200, f\"response code is {response.status_code}, not 200\"\n",
    "        return response.json().get('access_token')\n",
    "\n",
    "                \n",
    "    #make a function that takes a string and returns a string with the original semi-colon separated emails replaced with a list of emails with quotes around each\n",
    "    @staticmethod\n",
    "    def _mutate_email_list(s:str # a string like: ' ... \"emails\": [ ... \"address\": \"pam.jenkins@blackgold.ca;don.what@this.com\"}], ...  '\n",
    "                            ) -> str : # the same string but with ' ... \"address\": [\"pam.jenkins@blackgold.ca\", \"don.what@this.com\"]} ...\n",
    "        \"\"\" \n",
    "\n",
    "        \"\"\"\n",
    "        pat_s = r\"\"\"\\\"emails\\\": \\[.*?address\\\": (\\\"(?P<email1>.*?)\\\")\"\"\"\n",
    "        pattern=re.compile(pat_s)\n",
    "        matches = re.search(pattern,s) \n",
    "        if matches and matches.group(0) and matches.group(1) and matches.group(2):\n",
    "            og_emails_list_s = matches.group(2)\n",
    "            emails_l = [f\"\\\"{email}\\\"\" for email in og_emails_list_s.split(';')]\n",
    "            # emails_l = [f\"{email}\" for email in og_emails_list_s.split(';')]\n",
    "            emails_list_s = '[' +','.join(emails_l)+']'\n",
    "            return re.sub(matches.group(1), emails_list_s,s)\n",
    "        else:\n",
    "            return s\n",
    "    \n",
    "    def get_telus_data(self, \n",
    "                        obj: str, # telus endpoint \n",
    "                        offset :int = 0, # the row to begin retrieval\n",
    "                        since_date: str = \"\", # optionally, the date from which to retrieve\n",
    "                        count :int =1000 # the number of rows to retrieve\n",
    "                        ):\n",
    "        \"\"\"retrieve data from ATMS API, should be private method\n",
    "\n",
    "        Args:\n",
    "            obj (string): api endpoint to retrieve data from\n",
    "            offset (int, optional): first row to begin retrieval. Defaults to 0.\n",
    "            count (int, optional): number of rows to retrieve. Defaults to 1000.\n",
    "\n",
    "        Returns:\n",
    "            response object: response object from the API call\n",
    "        \"\"\"\n",
    "        vantix_data_url = f\"http://crm-api-telus.atmsplus.com/api/{obj}?offset={offset}&count={count}\"\n",
    "        if len(since_date)> 0:\n",
    "            vantix_data_url = f\"http://crm-api-telus.atmsplus.com/api/{obj}/lastupdate?count={count}&offset={offset}&updateDate={since_date}\"\n",
    "\n",
    "        v_headers = {'Authorization': f\"Bearer {self.telus_access_token}\"}\n",
    "\n",
    "        # print(vantix_data_url)    \n",
    "        response = requests.request(\"GET\", vantix_data_url, headers=v_headers, data={}).json()\n",
    "        \n",
    "        # inform caller we're done if we get fewer records than requested\n",
    "        return {\"response\": response, \"done\":  len(response) < count}\n",
    "\n",
    "    def retrieve_and_clean(self, \n",
    "                          obj : str = 'contacts', # ATMS object to retrieve\n",
    "                          initial_offset : int =0, # start retrieval at row initial_offset\n",
    "                          rows_per_batch :int =1000, # number records retrieved at once\n",
    "                          since_date : str = \"\", # if given, it will be used instead of `initial_offset` \n",
    "                          max_rows :int = 2000 # maximum number of rows to retrieve\n",
    "                          ):\n",
    "        \"\"\"Retrieve data from ATMS API, clean data and write to file\"\"\"\n",
    "        self.write_obj_to_file(obj, initial_offset, rows_per_batch, since_date, max_rows)\n",
    "        self.clean_data_file(obj)\n",
    "        self.load_data_file_to_dict(obj)\n",
    "\n",
    "    def write_obj_to_file(self, \n",
    "                          obj : str = 'contacts', # ATMS object to retrieve\n",
    "                          initial_offset : int =0, # start retrieval at row initial_offset\n",
    "                          rows_per_batch :int =1000, # number records retrieved at once\n",
    "                          since_date : str = \"\", # if given, it will be used instead of `initial_offset` \n",
    "                          max_rows :int = 2000 # maximum number of rows to retrieve\n",
    "                          ):\n",
    "        \"\"\"Retrieve data from ATMS API and write to file\n",
    "           private method\n",
    "\n",
    "        Args:\n",
    "            obj (string): a valid ATMS REST API object\n",
    "            rows_per_batch (int, optional): maximum number of rows to retieve. Defaults to 1000.\n",
    "        \"\"\"\n",
    "        done = False\n",
    "        # offset is the starting row for the next batch\n",
    "        offset = initial_offset \n",
    "\n",
    "        filename_s = f'atms_{obj}.json'\n",
    "        print('download dir is: ', self.download_dir)\n",
    "        file_path_s = os.path.join(self.download_dir, filename_s)\n",
    "        # print(\"Writing to file: \", file_path_s)\n",
    "        \n",
    "        with open(file_path_s, 'w') as f:\n",
    "            f.write(\"[ \\n\")\n",
    "            num_rows_for_next_batch = min(rows_per_batch, max_rows)\n",
    "            max_remaining_rows = max_rows\n",
    "            num_rows_for_next_batch = min(rows_per_batch, max_remaining_rows) \n",
    "            first_line = True\n",
    "            while (not done and (num_rows_for_next_batch > 0)):\n",
    "                # print('offset: ', offset)\n",
    "                # print('num rows already loaded: ', offset - initial_offset)\n",
    "                # print('num_rows_for_next_batch: ', num_rows_for_next_batch)\n",
    "                # print('max remaining rows: ', max_remaining_rows)\n",
    "\n",
    "                # read another batch\n",
    "                # the since_date parameter just acts like an initial offset, in theory we should be able \n",
    "                # to test it by making a small rows_per_batch \n",
    "                \n",
    "                print(f\"resp_d = self.get_telus_data({obj},offset={offset}, count= {num_rows_for_next_batch}, since_date={since_date})\")\n",
    "                resp_d = self.get_telus_data(obj,offset=offset, count= num_rows_for_next_batch, since_date=since_date)\n",
    "                obj_l = resp_d['response']\n",
    "                done = resp_d['done'] \n",
    "                s = \",\\n\".join([json.dumps(o) for o in obj_l])\n",
    "                if first_line:\n",
    "                    f.write(s)\n",
    "                    first_line = False\n",
    "                else:\n",
    "                    f.write(\",\\n\"+s)\n",
    "                offset += rows_per_batch\n",
    "                max_remaining_rows = max_rows - (offset - initial_offset)\n",
    "                num_rows_for_next_batch = min(rows_per_batch, max_remaining_rows)\n",
    "            f.write(\"\\n]\")\n",
    "    \n",
    "    \n",
    "    # def clean_obj_file(self, obj_s : str): \n",
    "    def clean_data_file(self, \n",
    "                        obj_s : str\n",
    "                        ): \n",
    "        \"\"\" Massage formatting to work with Salesfore Bulk API\n",
    "        \n",
    "        \"\"\"\n",
    "        # read original contacts file   \n",
    "        in_filename_s = f'atms_{obj_s}.json'\n",
    "        in_file_path_s = os.path.join(self.download_dir, in_filename_s)\n",
    "        print(\"cleaning_data_file - download dir is: \", self.download_dir)\n",
    "        # print(\"Cleaning file: \", in_file_path_s)\n",
    "        try:\n",
    "            with open(in_file_path_s,'r') as f:\n",
    "                # write modified contacts file \n",
    "                out_filename_s = f'atms_transformed_{obj_s}.json'\n",
    "                out_file_path_s = os.path.join(self.download_dir, out_filename_s)\n",
    "                print(\"creating file: \", out_file_path_s)\n",
    "                with open(out_file_path_s,'w') as f2:\n",
    "                    s = f.read()\n",
    "                    for l in s.split('\\n'):\n",
    "                        # remove \"O`Brien\" problem\n",
    "                        l2 = re.sub('\\u2019',\"'\",l)\n",
    "                        # fix emails\n",
    "                        new_s = ATMS_api._mutate_email_list(l2)+'\\n'\n",
    "                        f2.write(new_s)\n",
    "                print(f\"Finished cleaning {in_filename_s} -> {out_file_path_s}\")\n",
    "        except FileNotFoundError:\n",
    "            print('the files in our download dir:', os.listdir(self.download_dir) )\n",
    "            print('our in_file_path: ', in_file_path_s)\n",
    "               \n",
    "    \n",
    "    def load_data_file_to_dict(\n",
    "            self,\n",
    "            obj_s : str # ATMS object. eg. contacts|items|memberships|membership\n",
    "            ):\n",
    "            \"\"\" `load_data_file_to_dict` will attempt to load a cleaned json file into a dict for future parsing. \n",
    "            If the cleaned file doesn't exist, it will look for a dirty one to clean.\n",
    "            If the dirty once doesn't exist, it will raise an exception. It won't be downloaded because we don't know how much to get.\n",
    "            \n",
    "            \"\"\"\n",
    "            file_name_s = f'atms_transformed_{obj_s}.json'\n",
    "            file_path_s = os.path.join(self.download_dir, file_name_s)\n",
    "            print('Attempting to load: ', file_path_s)\n",
    "            data=\"\"\n",
    "            try:\n",
    "                with open(file_path_s, 'r') as f:\n",
    "                    data = f.read()\n",
    "            except FileNotFoundError:  # clean file not found\n",
    "                print(\"File not found. Check that the dirty file is there\")\n",
    "                dirty_file_name_s = f'atms_{obj_s}.json'\n",
    "                dirty_file_path_s = os.path.join(self.download_dir, dirty_file_name_s)\n",
    "\n",
    "                if os.path.exists(dirty_file_path_s):\n",
    "                    print(f\"found dirty file: {dirty_file_path_s}\")\n",
    "                    self.clean_data_file(obj_s)\n",
    "                    with open(file_path_s,'r') as f:\n",
    "                        data = f.read()\n",
    "                else:\n",
    "                    raise FileNotFoundError # we give up\n",
    "            finally: # this will be executed regardless of first 'try' failing or not\n",
    "                if len(data) > 0:\n",
    "                    try: # data might be buggy\n",
    "                        self.obj_d[obj_s] = json.loads(data)\n",
    "                    except json.JSONDecodeError:\n",
    "                        print(\"We've got buggy data, or something\")\n",
    "                        raise Exception('Data is not JSON formatted')\n",
    "                # assert obj_s in self.obj_d, f\" '{obj_s}' not in {self.obj_d.keys()}\"\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/josephsmann/doubledot/blob/master/doubledot/ATMS_api.py#L60){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ATMS_api.delete_all_data\n",
       "\n",
       ">      ATMS_api.delete_all_data ()\n",
       "\n",
       "delete all the subdirectories and files in the download directory"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/josephsmann/doubledot/blob/master/doubledot/ATMS_api.py#L60){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ATMS_api.delete_all_data\n",
       "\n",
       ">      ATMS_api.delete_all_data ()\n",
       "\n",
       "delete all the subdirectories and files in the download directory"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(ATMS_api.delete_all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File '/Users/josephmann/Documents/Github/doubledot/atms_download/910l1dey/atms_contacts.json' deleted successfully.\n",
      "File '/Users/josephmann/Documents/Github/doubledot/atms_download/910l1dey/atms_transformed_contacts.json' deleted successfully.\n",
      "Directory '/Users/josephmann/Documents/Github/doubledot/atms_download/910l1dey' deleted successfully.\n",
      "File '/Users/josephmann/Documents/Github/doubledot/atms_download/9k33wosx/atms_transformed_sales.json' deleted successfully.\n",
      "File '/Users/josephmann/Documents/Github/doubledot/atms_download/9k33wosx/atms_sales.json' deleted successfully.\n",
      "Directory '/Users/josephmann/Documents/Github/doubledot/atms_download/9k33wosx' deleted successfully.\n",
      "File '/Users/josephmann/Documents/Github/doubledot/atms_download/6pvz3y4l/atms_items.json' deleted successfully.\n",
      "File '/Users/josephmann/Documents/Github/doubledot/atms_download/6pvz3y4l/atms_contacts.json' deleted successfully.\n",
      "File '/Users/josephmann/Documents/Github/doubledot/atms_download/6pvz3y4l/atms_transformed_contacts.json' deleted successfully.\n",
      "File '/Users/josephmann/Documents/Github/doubledot/atms_download/6pvz3y4l/atms_memberships.json' deleted successfully.\n",
      "Directory '/Users/josephmann/Documents/Github/doubledot/atms_download/6pvz3y4l' deleted successfully.\n",
      "File '/Users/josephmann/Documents/Github/doubledot/atms_download/ha8bcu7t/atms_contacts.json' deleted successfully.\n",
      "File '/Users/josephmann/Documents/Github/doubledot/atms_download/ha8bcu7t/atms_transformed_contacts.json' deleted successfully.\n",
      "Directory '/Users/josephmann/Documents/Github/doubledot/atms_download/ha8bcu7t' deleted successfully.\n",
      "Directory '/Users/josephmann/Documents/Github/doubledot/atms_download/7mxag07l' deleted successfully.\n",
      "Directory '/Users/josephmann/Documents/Github/doubledot/atms_download' deleted successfully.\n"
     ]
    }
   ],
   "source": [
    "ATMS_api.delete_all_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory 'atms_download' already exists.\n",
      "my id is 5wsx6irr\n"
     ]
    }
   ],
   "source": [
    "atms = ATMS_api()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download dir is:  /Users/josephmann/Documents/Github/doubledot/atms_download/5wsx6irr\n",
      "resp_d = self.get_telus_data(contacts,offset=0, count= 1000, since_date=)\n",
      "resp_d = self.get_telus_data(contacts,offset=1000, count= 1000, since_date=)\n",
      "cleaning_data_file - download dir is:  /Users/josephmann/Documents/Github/doubledot/atms_download/5wsx6irr\n",
      "creating file:  /Users/josephmann/Documents/Github/doubledot/atms_download/5wsx6irr/atms_transformed_contacts.json\n",
      "Finished cleaning atms_contacts.json -> /Users/josephmann/Documents/Github/doubledot/atms_download/5wsx6irr/atms_transformed_contacts.json\n",
      "id is: 5wsx6irr\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['atms_contacts.json', 'atms_transformed_contacts.json']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atms.retrieve_and_clean()\n",
    "atms.list_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download dir is:  /Users/josephmann/Documents/Github/doubledot/atms_download/5wsx6irr\n",
      "resp_d = self.get_telus_data(contacts,offset=0, count= 1000, since_date=)\n",
      "resp_d = self.get_telus_data(contacts,offset=1000, count= 1000, since_date=)\n",
      "cleaning_data_file - download dir is:  /Users/josephmann/Documents/Github/doubledot/atms_download/5wsx6irr\n",
      "creating file:  /Users/josephmann/Documents/Github/doubledot/atms_download/5wsx6irr/atms_transformed_contacts.json\n",
      "Finished cleaning atms_contacts.json -> /Users/josephmann/Documents/Github/doubledot/atms_download/5wsx6irr/atms_transformed_contacts.json\n",
      "id is: 5wsx6irr\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['atms_contacts.json', 'atms_transformed_contacts.json']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atms.retrieve_and_clean()\n",
    "atms.list_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/josephsmann/doubledot/blob/master/doubledot/ATMS_api.py#L129){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ATMS_api.get_telus_data\n",
       "\n",
       ">      ATMS_api.get_telus_data (obj:str, offset:int=0, since_date:str='',\n",
       ">                               count:int=1000)\n",
       "\n",
       "retrieve data from ATMS API, should be private method\n",
       "\n",
       "Args:\n",
       "    obj (string): api endpoint to retrieve data from\n",
       "    offset (int, optional): first row to begin retrieval. Defaults to 0.\n",
       "    count (int, optional): number of rows to retrieve. Defaults to 1000.\n",
       "\n",
       "Returns:\n",
       "    response object: response object from the API call\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| obj | str |  | telus endpoint |\n",
       "| offset | int | 0 | the row to begin retrieval |\n",
       "| since_date | str |  | optionally, the date from which to retrieve |\n",
       "| count | int | 1000 | the number of rows to retrieve |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/josephsmann/doubledot/blob/master/doubledot/ATMS_api.py#L129){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ATMS_api.get_telus_data\n",
       "\n",
       ">      ATMS_api.get_telus_data (obj:str, offset:int=0, since_date:str='',\n",
       ">                               count:int=1000)\n",
       "\n",
       "retrieve data from ATMS API, should be private method\n",
       "\n",
       "Args:\n",
       "    obj (string): api endpoint to retrieve data from\n",
       "    offset (int, optional): first row to begin retrieval. Defaults to 0.\n",
       "    count (int, optional): number of rows to retrieve. Defaults to 1000.\n",
       "\n",
       "Returns:\n",
       "    response object: response object from the API call\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| obj | str |  | telus endpoint |\n",
       "| offset | int | 0 | the row to begin retrieval |\n",
       "| since_date | str |  | optionally, the date from which to retrieve |\n",
       "| count | int | 1000 | the number of rows to retrieve |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(ATMS_api.get_telus_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/josephsmann/doubledot/blob/master/doubledot/ATMS_api.py#L158){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ATMS_api.write_obj_to_file\n",
       "\n",
       ">      ATMS_api.write_obj_to_file (obj:str='contacts', initial_offset:int=0,\n",
       ">                                  rows_per_batch:int=1000, since_date:str='',\n",
       ">                                  max_rows:int=2000)\n",
       "\n",
       "Retrieve data from ATMS API and write to file\n",
       "   public method\n",
       "\n",
       "Args:\n",
       "    obj (string): a valid ATMS REST API object\n",
       "    rows_per_batch (int, optional): maximum number of rows to retieve. Defaults to 1000.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| obj | str | contacts | ATMS object to retrieve |\n",
       "| initial_offset | int | 0 | start retrieval at row initial_offset |\n",
       "| rows_per_batch | int | 1000 | number records retrieved at once |\n",
       "| since_date | str |  | if given, it will be used instead of `initial_offset` |\n",
       "| max_rows | int | 2000 | maximum number of rows to retrieve |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/josephsmann/doubledot/blob/master/doubledot/ATMS_api.py#L158){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ATMS_api.write_obj_to_file\n",
       "\n",
       ">      ATMS_api.write_obj_to_file (obj:str='contacts', initial_offset:int=0,\n",
       ">                                  rows_per_batch:int=1000, since_date:str='',\n",
       ">                                  max_rows:int=2000)\n",
       "\n",
       "Retrieve data from ATMS API and write to file\n",
       "   public method\n",
       "\n",
       "Args:\n",
       "    obj (string): a valid ATMS REST API object\n",
       "    rows_per_batch (int, optional): maximum number of rows to retieve. Defaults to 1000.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| obj | str | contacts | ATMS object to retrieve |\n",
       "| initial_offset | int | 0 | start retrieval at row initial_offset |\n",
       "| rows_per_batch | int | 1000 | number records retrieved at once |\n",
       "| since_date | str |  | if given, it will be used instead of `initial_offset` |\n",
       "| max_rows | int | 2000 | maximum number of rows to retrieve |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(ATMS_api.write_obj_to_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download dir is:  /Users/josephmann/Documents/Github/doubledot/atms_download/fd8bdlg7\n",
      "resp_d = self.get_telus_data(sales,offset=10, count= 3, since_date=2022-04-18)\n",
      "resp_d = self.get_telus_data(sales,offset=13, count= 3, since_date=2022-04-18)\n",
      "resp_d = self.get_telus_data(sales,offset=16, count= 3, since_date=2022-04-18)\n",
      "resp_d = self.get_telus_data(sales,offset=19, count= 1, since_date=2022-04-18)\n"
     ]
    }
   ],
   "source": [
    "obj = 'sales'\n",
    "count = 3\n",
    "offset = 10\n",
    "since_date = '2022-04-18'\n",
    "\n",
    "atms.clean_data_dir(obj)\n",
    "atms.write_obj_to_file(obj, initial_offset=offset, rows_per_batch=3, max_rows=10, since_date=since_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/josephsmann/doubledot/blob/master/doubledot/ATMS_api.py#L51){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ATMS_api.list_files\n",
       "\n",
       ">      ATMS_api.list_files ()\n",
       "\n",
       "returns list of files in download folder"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/josephsmann/doubledot/blob/master/doubledot/ATMS_api.py#L51){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ATMS_api.list_files\n",
       "\n",
       ">      ATMS_api.list_files ()\n",
       "\n",
       "returns list of files in download folder"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(ATMS_api.list_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id is: fd8bdlg7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['atms_sales.json']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atms.list_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### ATMS_api.load_data_file_to_dict\n",
       "\n",
       ">      ATMS_api.load_data_file_to_dict (obj_s:str)\n",
       "\n",
       "`load_data_file_to_dict` will attempt to load a cleaned json file into a dict for future parsing. \n",
       "If the cleaned file doesn't exist, it will look for a dirty one to clean.\n",
       "If the dirty once doesn't exist, it will raise an exception. It won't be downloaded because we don't know how much to get.\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| obj_s | str | ATMS object. eg. contacts\\|items\\|memberships\\|membership |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### ATMS_api.load_data_file_to_dict\n",
       "\n",
       ">      ATMS_api.load_data_file_to_dict (obj_s:str)\n",
       "\n",
       "`load_data_file_to_dict` will attempt to load a cleaned json file into a dict for future parsing. \n",
       "If the cleaned file doesn't exist, it will look for a dirty one to clean.\n",
       "If the dirty once doesn't exist, it will raise an exception. It won't be downloaded because we don't know how much to get.\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| obj_s | str | ATMS object. eg. contacts\\|items\\|memberships\\|membership |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(ATMS_api.load_data_file_to_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fd8bdlg7\n",
      "Attempting to load:  /Users/josephmann/Documents/Github/doubledot/atms_download/fd8bdlg7/atms_transformed_sales.json\n",
      "File not found. Check that the dirty file is there\n",
      "found dirty file: /Users/josephmann/Documents/Github/doubledot/atms_download/fd8bdlg7/atms_sales.json\n",
      "cleaning_data_file - download dir is:  /Users/josephmann/Documents/Github/doubledot/atms_download/fd8bdlg7\n",
      "creating file:  /Users/josephmann/Documents/Github/doubledot/atms_download/fd8bdlg7/atms_transformed_sales.json\n",
      "Finished cleaning atms_sales.json -> /Users/josephmann/Documents/Github/doubledot/atms_download/fd8bdlg7/atms_transformed_sales.json\n"
     ]
    }
   ],
   "source": [
    "print(atms.id)\n",
    "atms.load_data_file_to_dict(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['sales'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atms.obj_d.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/josephsmann/doubledot/blob/master/doubledot/ATMS_api.py#L214){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ATMS_api.clean_data_file\n",
       "\n",
       ">      ATMS_api.clean_data_file (obj_s:str)\n",
       "\n",
       "clean up the atms_contacts.json file, this is necessary before loading into Saleforce"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/josephsmann/doubledot/blob/master/doubledot/ATMS_api.py#L214){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ATMS_api.clean_data_file\n",
       "\n",
       ">      ATMS_api.clean_data_file (obj_s:str)\n",
       "\n",
       "clean up the atms_contacts.json file, this is necessary before loading into Saleforce"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(ATMS_api.clean_data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/josephsmann/doubledot/blob/master/doubledot/ATMS_api.py#L73){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ATMS_api.clean_data_dir\n",
       "\n",
       ">      ATMS_api.clean_data_dir (obj_s:str=None)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/josephsmann/doubledot/blob/master/doubledot/ATMS_api.py#L73){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ATMS_api.clean_data_dir\n",
       "\n",
       ">      ATMS_api.clean_data_dir (obj_s:str=None)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(ATMS_api.clean_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vantix",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
