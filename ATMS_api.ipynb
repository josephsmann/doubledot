{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ATMS_api\n",
    "\n",
    "> functions for access ATMS_api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp ATMS_api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "from nbdev.showdoc import *\n",
    "import requests\n",
    "import json\n",
    "import jmespath as jp\n",
    "import re\n",
    "from time import sleep\n",
    "from fastcore.basics import patch\n",
    "import fileinput\n",
    "import pandas as pd\n",
    "import os\n",
    "from fastcore.test import test_eq\n",
    "import glob\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class ATMS_api:\n",
    "    class_download_dir = os.path.join(os.getcwd(),'atms_download')\n",
    "\n",
    "    def __init__(self):\n",
    "        self.telus_access_token = ATMS_api.get_atms_authentication()\n",
    "        self.obj_d = {}\n",
    "\n",
    "        # create unique download directory per instance\n",
    "        if not os.path.exists(ATMS_api.class_download_dir):\n",
    "            os.makedirs(ATMS_api.class_download_dir)\n",
    "            print(f\"Directory 'atms_download' created successfully.\")\n",
    "        else:\n",
    "            print(f\"Directory 'atms_download' already exists.\")\n",
    "\n",
    "        # Alternatively, generate a unique file name with a random string\n",
    "        random_string = ''.join(random.choices('abcdefghijklmnopqrstuvwxyz0123456789', k=8))\n",
    "        self.download_dir  = os.path.join(ATMS_api.class_download_dir, random_string)\n",
    "\n",
    "        # Check if the new file director already exists in the directory\n",
    "        while os.path.exists(self.download_dir):\n",
    "            # If the file name already exists, generate a new one\n",
    "            random_string  = ''.join(random.choices('abcdefghijklmnopqrstuvwxyz0123456789', k=8))\n",
    "            self.download_dir  = os.path.join(ATMS_api.class_download_dir, random_string)\n",
    "        \n",
    "        os.mkdir(self.download_dir)\n",
    "        self.id = random_string\n",
    "        print(\"my id is\", self.id)\n",
    "        \n",
    "    def list_files(self):\n",
    "        \"\"\" returns list of files in download folder \"\"\"\n",
    "        print('id is:', self.id)\n",
    "        return os.listdir(self.download_dir)\n",
    "    \n",
    "    def clean_data_dir(self,\n",
    "                       obj_s: str = None):\n",
    "        glob_s = os.path.join(self.download_dir, f\"*{obj_s if obj_s else ''}*.json\")\n",
    "        file_l = glob.glob(glob_s)\n",
    "        # print(file_l)\n",
    "        for file_path in file_l:\n",
    "            if os.path.isfile(file_path):\n",
    "                os.remove(file_path)\n",
    "                print(f\"File '{file_path}' deleted successfully.\")\n",
    "\n",
    "\n",
    "    @staticmethod    \n",
    "    def get_atms_authentication():\n",
    "        \"\"\"get access token for ATMS API\n",
    "\n",
    "        Returns:\n",
    "            response object: response object from the API call \n",
    "        \"\"\"\n",
    "        vantix_url = \"http://crm-api-telus.atmsplus.com/auth\"\n",
    "        \n",
    "        with open('secrets.json') as f:\n",
    "            secrets = json.load(f)\n",
    "\n",
    "        payload = json.dumps({\n",
    "            \"username\": secrets['vantix_user'],\n",
    "            \"password\": secrets['vantix_pw'],\n",
    "            \"rememberMe\": True\n",
    "        })\n",
    "        headers = {\n",
    "            'Content-Type': 'application/json'\n",
    "        }\n",
    "\n",
    "        response = requests.request(\"POST\", vantix_url, headers=headers, data=payload)\n",
    "        assert response.status_code == 200, f\"response code is {response.status_code}, not 200\"\n",
    "        return response.json().get('access_token')\n",
    "\n",
    "                \n",
    "    #make a function that takes a string and returns a string with the original semi-colon separated emails replaced with a list of emails with quotes around each\n",
    "    @staticmethod\n",
    "    def _mutate_email_list(s:str # a string like: ' ... \"emails\": [ ... \"address\": \"pam.jenkins@blackgold.ca;don.what@this.com\"}], ...  '\n",
    "                            ) -> str : # the same string but with ' ... \"address\": [\"pam.jenkins@blackgold.ca\", \"don.what@this.com\"]} ...\n",
    "        \"\"\" \n",
    "\n",
    "        \"\"\"\n",
    "        pat_s = r\"\"\"\\\"emails\\\": \\[.*?address\\\": (\\\"(?P<email1>.*?)\\\")\"\"\"\n",
    "        pattern=re.compile(pat_s)\n",
    "        matches = re.search(pattern,s) \n",
    "        if matches and matches.group(0) and matches.group(1) and matches.group(2):\n",
    "            og_emails_list_s = matches.group(2)\n",
    "            emails_l = [f\"\\\"{email}\\\"\" for email in og_emails_list_s.split(';')]\n",
    "            # emails_l = [f\"{email}\" for email in og_emails_list_s.split(';')]\n",
    "            emails_list_s = '[' +','.join(emails_l)+']'\n",
    "            return re.sub(matches.group(1), emails_list_s,s)\n",
    "        else:\n",
    "            return s\n",
    "    \n",
    "    def _get_telus_data(self, \n",
    "                        obj: str, # telus endpoint \n",
    "                        offset :int = 0, # the row to begin retrieval\n",
    "                        since_date: str = \"\", # optionally, the date from which to retrieve\n",
    "                        count :int =1000 # the number of rows to retrieve\n",
    "                        ):\n",
    "        \"\"\"retrieve data from ATMS API, should be private method\n",
    "\n",
    "        Args:\n",
    "            obj (string): api endpoint to retrieve data from\n",
    "            offset (int, optional): first row to begin retrieval. Defaults to 0.\n",
    "            count (int, optional): number of rows to retrieve. Defaults to 1000.\n",
    "\n",
    "        Returns:\n",
    "            response object: response object from the API call\n",
    "        \"\"\"\n",
    "        vantix_data_url = f\"http://crm-api-telus.atmsplus.com/api/{obj}?offset={offset}&count={count}\"\n",
    "        if len(since_date)> 0:\n",
    "            vantix_data_url = f\"http://crm-api-telus.atmsplus.com/api/{obj}/lastupdate?count={count}&offset={offset}&updateDate={since_date}\"\n",
    "\n",
    "        v_headers = {'Authorization': f\"Bearer {self.telus_access_token}\"}\n",
    "\n",
    "        # print(vantix_data_url)    \n",
    "        response = requests.request(\"GET\", vantix_data_url, headers=v_headers, data={}).json()\n",
    "        \n",
    "        # inform caller we're done if we get fewer records than requested\n",
    "        return {\"response\": response, \"done\":  len(response) < count}\n",
    "\n",
    "\n",
    "    def write_obj_to_file(self, \n",
    "                          obj : str = 'contacts', # ATMS object to retrieve\n",
    "                          initial_offset : int =0, # start retrieval at row initial_offset\n",
    "                          rows_per_batch :int =1000, # number records retrieved at once\n",
    "                          since_date : str = \"\", # if given, it will be used instead of `initial_offset` \n",
    "                          max_rows :int = 2000 # maximum number of rows to retrieve\n",
    "                          ):\n",
    "        \"\"\"Retrieve data from ATMS API and write to file\n",
    "           public method\n",
    "\n",
    "        Args:\n",
    "            obj (string): a valid ATMS REST API object\n",
    "            rows_per_batch (int, optional): maximum number of rows to retieve. Defaults to 1000.\n",
    "\n",
    "        ---- working on since_date..\n",
    "        idea: just generalize the offset variable\n",
    "        first: get __get_telus_data working with since_date\n",
    "        \"\"\"\n",
    "        done = False\n",
    "        # offset is the starting row for the next batch\n",
    "        offset = initial_offset \n",
    "\n",
    "        filename_s = f'atms_{obj}.json'\n",
    "        print('download dir is: ', self.download_dir)\n",
    "        file_path_s = os.path.join(self.download_dir, filename_s)\n",
    "        # print(\"Writing to file: \", file_path_s)\n",
    "        \n",
    "        with open(file_path_s, 'w') as f:\n",
    "            f.write(\"[ \\n\")\n",
    "            num_rows_for_next_batch = min(rows_per_batch, max_rows)\n",
    "            max_remaining_rows = max_rows\n",
    "            num_rows_for_next_batch = min(rows_per_batch, max_remaining_rows) \n",
    "            first_line = True\n",
    "            while (not done and (num_rows_for_next_batch > 0)):\n",
    "                # print('offset: ', offset)\n",
    "                # print('num rows already loaded: ', offset - initial_offset)\n",
    "                # print('num_rows_for_next_batch: ', num_rows_for_next_batch)\n",
    "                # print('max remaining rows: ', max_remaining_rows)\n",
    "\n",
    "                # read another batch\n",
    "                resp_d = self._get_telus_data(obj,offset=offset, count= num_rows_for_next_batch)\n",
    "                obj_l = resp_d['response']\n",
    "                done = resp_d['done'] \n",
    "                s = \",\\n\".join([json.dumps(o) for o in obj_l])\n",
    "                if first_line:\n",
    "                    f.write(s)\n",
    "                    first_line = False\n",
    "                else:\n",
    "                    f.write(\",\\n\"+s)\n",
    "                offset += rows_per_batch\n",
    "                max_remaining_rows = max_rows - (offset - initial_offset)\n",
    "                num_rows_for_next_batch = min(rows_per_batch, max_remaining_rows)\n",
    "            f.write(\"\\n]\")\n",
    "    \n",
    "    \n",
    "    # def clean_obj_file(self, obj_s : str): \n",
    "    def clean_data_file(self, obj_s : str): \n",
    "        \"\"\"clean up the atms_contacts.json file, this is necessary before loading into Saleforce\n",
    "        \n",
    "        \"\"\"\n",
    "        # read original contacts file   \n",
    "        in_filename_s = f'atms_{obj_s}.json'\n",
    "        in_file_path_s = os.path.join(self.download_dir, in_filename_s)\n",
    "        print(\"cleaning_data_file - download dir is: \", self.download_dir)\n",
    "        # print(\"Cleaning file: \", in_file_path_s)\n",
    "        try:\n",
    "            with open(in_file_path_s,'r') as f:\n",
    "                # write modified contacts file \n",
    "                out_filename_s = f'atms_transformed_{obj_s}.json'\n",
    "                out_file_path_s = os.path.join(self.download_dir, out_filename_s)\n",
    "                print(\"creating file: \", out_file_path_s)\n",
    "                with open(out_file_path_s,'w') as f2:\n",
    "                    s = f.read()\n",
    "                    for l in s.split('\\n'):\n",
    "                        # remove \"O`Brien\" problem\n",
    "                        l2 = re.sub('\\u2019',\"'\",l)\n",
    "                        # fix emails\n",
    "                        new_s = ATMS_api._mutate_email_list(l2)+'\\n'\n",
    "                        f2.write(new_s)\n",
    "                print(f\"Finished cleaning {in_filename_s} -> {out_file_path_s}\")\n",
    "        except FileNotFoundError:\n",
    "            print('the files in our download dir:', os.listdir(self.download_dir) )\n",
    "            print('our in_file_path: ', in_file_path_s)\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory 'atms_download' already exists.\n",
      "my id is tfkqrzu1\n"
     ]
    }
   ],
   "source": [
    "atms = ATMS_api()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i'm hoping this won't get exported\n",
    "obj = 'sales'\n",
    "# obj = 'contacts'\n",
    "count = 3\n",
    "offset = 10\n",
    "since_date = ''\n",
    "# since_date = '2022-04-18T14:51:31.133' # this works, lets try a simpler one\n",
    "since_date = '2022-04-18'\n",
    "\n",
    "\n",
    "vantix_data_url = f\"http://crm-api-telus.atmsplus.com/api/{obj}?offset={offset}&count={count}\"\n",
    "if len(since_date)> 0:\n",
    "    vantix_data_url = f\"http://crm-api-telus.atmsplus.com/api/{obj}/lastupdate?count={count}&offset={offset}&updateDate={since_date}\"\n",
    "\n",
    "v_headers = {'Authorization': f\"Bearer {atms.telus_access_token}\"}\n",
    "\n",
    "# print(vantix_data_url)    \n",
    "response = requests.request(\"GET\", vantix_data_url, headers=v_headers, data={}).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2020707'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response[0]['saleKey']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2020697'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response[0]['saleKey']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "# make dict from json file\n",
    " \n",
    "@patch\n",
    "def load_data_file_to_dict(\n",
    "        self: ATMS_api, \n",
    "        obj_s : str # ATMS object. eg. contacts|items|memberships|membership\n",
    "        ):\n",
    "        \"\"\" load_data_file_to_dict will attempt to load a cleaned json file into a dict for future parsing. \n",
    "         If the cleaned file doesn't exist, it will look for a dirty one to clean.\n",
    "         If the dirty once doesn't exist, it will raise an exception. It won't be downloaded because we don't know how much to get.\n",
    "          \n",
    "        \"\"\"\n",
    "        file_name_s = f'atms_transformed_{obj_s}.json'\n",
    "        file_path_s = os.path.join(self.download_dir, file_name_s)\n",
    "        print('Attempting to load: ', file_path_s)\n",
    "        data=\"\"\n",
    "        try:\n",
    "            with open(file_path_s, 'r') as f:\n",
    "                data = f.read()\n",
    "        except FileNotFoundError:  # clean file not found\n",
    "            print(\"File not found. Check that the dirty file is there\")\n",
    "            dirty_file_name_s = f'atms_{obj_s}.json'\n",
    "            dirty_file_path_s = os.path.join(self.download_dir, dirty_file_name_s)\n",
    "\n",
    "            if os.path.exists(dirty_file_path_s):\n",
    "                print(f\"found dirty file: {dirty_file_path_s}\")\n",
    "                self.clean_data_file(obj_s)\n",
    "                with open(file_path_s,'r') as f:\n",
    "                    data = f.read()\n",
    "            else:\n",
    "                raise FileNotFoundError # we give up\n",
    "        finally: # this will be executed regardless of first 'try' failing or not\n",
    "            if len(data) > 0:\n",
    "                try: # data might be buggy\n",
    "                    self.obj_d[obj_s] = json.loads(data)\n",
    "                except json.JSONDecodeError:\n",
    "                    print(\"We've got buggy data, or something\")\n",
    "                    raise Exception('Data is not JSON formatted')\n",
    "            # assert obj_s in self.obj_d, f\" '{obj_s}' not in {self.obj_d.keys()}\"\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/josephsmann/doubledot/blob/master/doubledot/ATMS_api.py#L125){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ATMS_api.write_obj_to_file\n",
       "\n",
       ">      ATMS_api.write_obj_to_file (obj:str='contacts', initial_offset:int=0,\n",
       ">                                  rows_per_batch:int=1000, max_rows:int=2000)\n",
       "\n",
       "Retrieve data from ATMS API and write to file\n",
       "   public method\n",
       "\n",
       "Args:\n",
       "    obj (string): a valid ATMS REST API object\n",
       "    rows_per_batch (int, optional): maximum number of rows to retieve. Defaults to 1000.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| obj | str | contacts | ATMS object to retrieve |\n",
       "| initial_offset | int | 0 | start retrieval at row initial_offset |\n",
       "| rows_per_batch | int | 1000 | number records retrieved at once |\n",
       "| max_rows | int | 2000 | maximum number of rows to retrieve |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/josephsmann/doubledot/blob/master/doubledot/ATMS_api.py#L125){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ATMS_api.write_obj_to_file\n",
       "\n",
       ">      ATMS_api.write_obj_to_file (obj:str='contacts', initial_offset:int=0,\n",
       ">                                  rows_per_batch:int=1000, max_rows:int=2000)\n",
       "\n",
       "Retrieve data from ATMS API and write to file\n",
       "   public method\n",
       "\n",
       "Args:\n",
       "    obj (string): a valid ATMS REST API object\n",
       "    rows_per_batch (int, optional): maximum number of rows to retieve. Defaults to 1000.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| obj | str | contacts | ATMS object to retrieve |\n",
       "| initial_offset | int | 0 | start retrieval at row initial_offset |\n",
       "| rows_per_batch | int | 1000 | number records retrieved at once |\n",
       "| max_rows | int | 2000 | maximum number of rows to retrieve |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(ATMS_api.write_obj_to_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test of _mutate_mail_list func\n",
    "s  = ' \"emails\": [{\"emailId\": 12956, \"contactKey\": 83, \"emailType\": \"E-Mail\", \"address\": \"pam.jenkins@blackgold.ca;joe.what@this.that\"}], \"faxes\": [{\"faxId'\n",
    "s2 = ' \"emails\": [{\"emailId\": 12956, \"contactKey\": 83, \"emailType\": \"E-Mail\", \"address\": [\"pam.jenkins@blackgold.ca\",\"joe.what@this.that\"]}], \"faxes\": [{\"faxId'\n",
    "test_eq(ATMS_api._mutate_email_list(s), s2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "## need to make test for this because it feels like its failing\n",
    "# print(\"called from ATMS_api.ipynb\")\n",
    "# ATMS_api.clean_data_dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/josephsmann/doubledot/blob/master/doubledot/ATMS_api.py#L175){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ATMS_api.clean_data_file\n",
       "\n",
       ">      ATMS_api.clean_data_file (obj_s:str)\n",
       "\n",
       "clean up the atms_contacts.json file, this is necessary before loading into Saleforce"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/josephsmann/doubledot/blob/master/doubledot/ATMS_api.py#L175){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ATMS_api.clean_data_file\n",
       "\n",
       ">      ATMS_api.clean_data_file (obj_s:str)\n",
       "\n",
       "clean up the atms_contacts.json file, this is necessary before loading into Saleforce"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(ATMS_api.clean_data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/josephsmann/doubledot/blob/master/doubledot/ATMS_api.py#L44){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ATMS_api.clean_data_dir\n",
       "\n",
       ">      ATMS_api.clean_data_dir (obj_s:str=None)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/josephsmann/doubledot/blob/master/doubledot/ATMS_api.py#L44){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ATMS_api.clean_data_dir\n",
       "\n",
       ">      ATMS_api.clean_data_dir (obj_s:str=None)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(ATMS_api.clean_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vantix",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
