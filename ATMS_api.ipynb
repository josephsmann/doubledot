{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# doubledot.ATMS\n",
    "\n",
    ">  Definition of the ATMS_api class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp ATMS_api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "from nbdev.showdoc import *\n",
    "import requests\n",
    "import json\n",
    "import jmespath as jp\n",
    "import re\n",
    "from time import sleep\n",
    "from fastcore.basics import patch\n",
    "import fileinput\n",
    "import pandas as pd\n",
    "import os\n",
    "from fastcore.test import test_eq\n",
    "import glob\n",
    "import time\n",
    "import random\n",
    "from pyisemail import is_email\n",
    "from dataclasses import dataclass, field\n",
    "from collections import namedtuple, UserDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "api_s = \"http://crm-api-neaq.atmsplus.com/\"\n",
    "\n",
    "class ATMS_d(dict):\n",
    "    \"\"\"A dictionary that allows dot notation access to its keys and values.\n",
    "    \"\"\"\n",
    "\n",
    "    key_l = ['contacts','memberships','sales','items']\n",
    "    def __init__(self, val=None):\n",
    "        if val is None:\n",
    "            val = {'contacts':{},'memberships':{},'sales':{},'items':{}}\n",
    "        super().__init__(val)\n",
    "\n",
    "    # dot notation access\n",
    "    def __getitem__(self, item):\n",
    "        # print('get with []', item, self)\n",
    "        if item not in self.key_l:\n",
    "            raise KeyError(f'\\\"{item}\\\" must be one of: {\", \".join(self.key_l)}')\n",
    "        return super().__getitem__(item )\n",
    "    \n",
    "    def __setitem__(self, item, value):\n",
    "        print('set with []')\n",
    "        if item not in self.key_l:\n",
    "            raise KeyError(f'\\\"{item}\\\" must be one of: {\", \".join(self.key_l)}')\n",
    "        super().__setitem__(item, value)\n",
    "\n",
    "    # [] notation access\n",
    "    def __delitem__(self, item):\n",
    "        super().__delitem__(item)\n",
    "    \n",
    "    # [] notation access\n",
    "    def __getattr__(self, key):\n",
    "        try:\n",
    "            return self[key]\n",
    "        except KeyError as k:\n",
    "            raise AttributeError(k)\n",
    "\n",
    "    # dot notation access   \n",
    "    def __setattr__(self, key, value):\n",
    "        self[key] = value\n",
    "\n",
    "    def __delattr__(self, key):\n",
    "        try:\n",
    "            del self[key]\n",
    "        except KeyError as k:\n",
    "            raise AttributeError(k)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '<ATMS ' + dict.__repr__(self) + '>'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class ATMS_api:\n",
    "    class_download_dir = os.path.join(os.getcwd(),'atms_download')\n",
    "    \n",
    "    @property\n",
    "    def telus_access_token(self):\n",
    "        if self._telus_access_token is None:\n",
    "            self._telus_access_token = ATMS_api.get_atms_authentication()\n",
    "        return self._telus_access_token\n",
    "\n",
    "    @staticmethod\n",
    "    def delete_all_data():\n",
    "        \"\"\" delete all the subdirectories and files in the download directory \"\"\"\n",
    "        for dir_path in glob.glob(os.path.join(ATMS_api.class_download_dir, \"*\")):\n",
    "            if os.path.isdir(dir_path):\n",
    "                for file_path in glob.glob(os.path.join(dir_path, \"*\")):\n",
    "                    if os.path.isfile(file_path):\n",
    "                        os.remove(file_path)\n",
    "                        print(f\"File '{file_path}' deleted successfully.\")\n",
    "                os.removedirs(dir_path) \n",
    "                print(f\"Directory '{dir_path}' deleted successfully.\")  \n",
    "        print(f\"Directory '{ATMS_api.class_download_dir}' deleted successfully.\")   \n",
    "\n",
    "\n",
    "\n",
    "    @staticmethod    \n",
    "    def get_atms_authentication():\n",
    "        \"\"\"get access token for ATMS API\n",
    "\n",
    "        Returns:\n",
    "            response object: response object from the API call \n",
    "        \"\"\"\n",
    "        vantix_url = \"http://crm-api-telus.atmsplus.com/auth\"\n",
    "        \n",
    "        with open('secrets.json') as f:\n",
    "            secrets = json.load(f)\n",
    "\n",
    "        payload = json.dumps({\n",
    "            \"username\": secrets['vantix_user'],\n",
    "            \"password\": secrets['vantix_pw'],\n",
    "            \"rememberMe\": True\n",
    "        })\n",
    "        headers = {\n",
    "            'Content-Type': 'application/json'\n",
    "        }\n",
    "\n",
    "        response = requests.request(\"POST\", vantix_url, headers=headers, data=payload)\n",
    "        assert response.status_code == 200, f\"response code is {response.status_code}, not 200\"\n",
    "        return response.json().get('access_token')\n",
    "\n",
    "                \n",
    "    #make a function that takes a string and returns a string with the original semi-colon separated emails replaced with a list of emails with quotes around each\n",
    "\n",
    "    @staticmethod\n",
    "    def _mutate_email_list(s:str # a string like: ' ... \"emails\": [ ... \"address\": \"pam.jenkins@blackgold.ca;don.what@this.com\"}], ...  '\n",
    "                            ) -> str : # the same string but with ' ... \"address\": [\"pam.jenkins@blackgold.ca\", \"don.what@this.com\"]} ...\n",
    "        \"\"\" \n",
    "\n",
    "        \"\"\"\n",
    "        pat_s = r\"\"\"\\\"emails\\\": \\[.*?address\\\": (\\\"(?P<email1>.*?)\\\")\"\"\"\n",
    "        pattern=re.compile(pat_s)\n",
    "        matches = re.search(pattern,s) \n",
    "        if matches and matches.group(0) and matches.group(1) and matches.group(2):\n",
    "            og_emails_list_s = matches.group(2)\n",
    "            # emails_l = [f\"\\\"{email}\\\"\" for email in og_emails_list_s.split(';')]\n",
    "            emails_l = [f\"\\\"{email}\\\"\" for email in og_emails_list_s.split(';') if is_email(email)]\n",
    "            # emails_l = [f\"{email}\" for email in og_emails_list_s.split(';')]\n",
    "            emails_list_s = '[' +','.join(emails_l)+']'\n",
    "            return re.sub(matches.group(1), emails_list_s,s)\n",
    "        else:\n",
    "            return s\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `__init__`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def __init__(self:ATMS_api, data_dir: str = None ):\n",
    "    # if telus_access_token is None:\n",
    "    #     self.telus_access_token = ATMS_api.get_atms_authentication()\n",
    "    # else:\n",
    "    #     self.telus_access_token = telus_access_token\n",
    "    self._telus_access_token = None\n",
    "\n",
    "\n",
    "    # object keys shoud be ['memberships', 'sales', 'items', 'contacts']\n",
    "    # i'eg ; https://goodcode.io/articles/python-dict-object/\n",
    "    # self.data = ATMS_data()\n",
    "    # self.obj_d = {'contacts': self.data.contacts, 'sales': self.data.sales, 'memberships': self.data.memberships, 'items': self.data.items}\n",
    "    self.obj_d = ATMS_d()\n",
    "\n",
    "    # create unique download directory per instance\n",
    "    if not os.path.exists(ATMS_api.class_download_dir):\n",
    "        os.makedirs(ATMS_api.class_download_dir)\n",
    "        print(f\"Directory 'atms_download' created successfully.\")\n",
    "    else:\n",
    "        print(f\"Directory 'atms_download' already exists.\")\n",
    "\n",
    "    if data_dir is None:\n",
    "        # generate a unique directory name with a random string\n",
    "        random_string = ''.join(random.choices('abcdefghijklmnopqrstuvwxyz0123456789', k=8))\n",
    "        self.download_dir  = os.path.join(ATMS_api.class_download_dir, random_string)\n",
    "\n",
    "        # Check if the new director already exists in the directory\n",
    "        while os.path.exists(self.download_dir):\n",
    "            # If the directory name already exists, generate a new one\n",
    "            random_string  = ''.join(random.choices('abcdefghijklmnopqrstuvwxyz0123456789', k=8))\n",
    "            self.download_dir  = os.path.join(ATMS_api.class_download_dir, random_string)\n",
    "        \n",
    "        os.mkdir(self.download_dir)\n",
    "        self.id = random_string\n",
    "    else:\n",
    "        self.download_dir  = os.path.join(ATMS_api.class_download_dir, data_dir)\n",
    "        self.id = data_dir\n",
    "        \n",
    "    print(\"my id is\", self.id)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ``set_atms_id`` \n",
    "> is a method that sets the atms_id and download_dir for the instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def set_atms_id(self:ATMS_api, atms_id:str):\n",
    "    \"\"\" set the atms_id and download_dir for the instance \"\"\"\n",
    "    self.atms_id = atms_id\n",
    "    self.download_dir  = os.path.join(ATMS_api.class_download_dir, atms_id)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## list_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch    \n",
    "def list_files(self:ATMS_api):\n",
    "    \"\"\" returns list of files in download folder \"\"\"\n",
    "    print('id is:', self.id)\n",
    "    if os.path.exists(self.download_dir):\n",
    "        return os.listdir(self.download_dir)\n",
    "    else:\n",
    "        return []\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## clean_data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export    \n",
    "@patch\n",
    "def clean_data_dir(self:ATMS_api,\n",
    "                    obj_s: str = None):\n",
    "    glob_s = os.path.join(self.download_dir, f\"*{obj_s if obj_s else ''}*.json\")\n",
    "    file_l = glob.glob(glob_s)\n",
    "    # print(file_l)\n",
    "    for file_path in file_l:\n",
    "        if os.path.isfile(file_path):\n",
    "            os.remove(file_path)\n",
    "            print(f\"File '{file_path}' deleted successfully.\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get_telus_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export    \n",
    "@patch\n",
    "def get_telus_data(self:ATMS_api, \n",
    "                    obj: str, # telus endpoint \n",
    "                    offset :int = 0, # the row to begin retrieval\n",
    "                    since_date: str = \"\", # optionally, the date from which to retrieve\n",
    "                    count :int =1, # the number of rows to retrieve\n",
    "                    contact_id: int = None # the contact id to retrieve\n",
    "                    ):\n",
    "    \"\"\"retrieve data from ATMS API, should be private method\n",
    "\n",
    "    Args:\n",
    "        obj (string): api endpoint to retrieve data from\n",
    "        offset (int, optional): first row to begin retrieval. Defaults to 0.\n",
    "        count (int, optional): number of rows to retrieve. Defaults to 1000.\n",
    "\n",
    "    Returns:\n",
    "        a dict with two keys: \"response\" and \"done\". \n",
    "        \"response\" is the response object from the API call. \"done\" is a boolean indicating whether there are more records to retrieve.\n",
    "    \"\"\"\n",
    "    vantix_data_url = f\"{api_s}api/{obj}?offset={offset}&count={count}\"\n",
    "    if len(since_date)> 0:\n",
    "        print(\"ATMS_api.get_telus_data: since_date is\", since_date)\n",
    "        vantix_data_url = f\"{api_s}api/{obj}/lastupdate?count={count}&offset={offset}&updateDate={since_date}\"\n",
    "    \n",
    "    if contact_id:\n",
    "        print('we have contact_id', contact_id, 'and obj is', obj)\n",
    "        ## if contact id and obj == 'contacts' everything else is ignored\n",
    "        if obj=='contacts':\n",
    "            print('we have contact_id and obj is contacts')\n",
    "            vantix_data_url = f\"{api_s}api/{obj}/{contact_id}\"\n",
    "            print(\"ATMS_api.get_telus_data : \", vantix_data_url)\n",
    "\n",
    "        ## if contact id everything else is ignored\n",
    "        elif obj=='sales' or obj=='memberships':\n",
    "            vantix_data_url = f\"{api_s}api/{obj}/contact/{contact_id}\"\n",
    "        else:\n",
    "            raise ValueError(\"contact_id is only valid for 'contacts' and 'sales'\")\n",
    "\n",
    "    v_headers = {'Authorization': f\"Bearer {self.telus_access_token}\"}\n",
    "\n",
    "    print(vantix_data_url)    \n",
    "    # response = requests.request(\"GET\", vantix_data_url, headers=v_headers, data={}).json()\n",
    "    response = requests.request(\"GET\", vantix_data_url, headers=v_headers, data={})\n",
    "    \n",
    "    # inform caller we're done if we get fewer records than requested\n",
    "    # BUT there could still be an error in the response\n",
    "    return {\"response\": response, \"done\":  response.status_code!=200 or len(response.json()) < count}\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## retrieve_and_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export    \n",
    "@patch\n",
    "def retrieve_and_clean(self:ATMS_api, \n",
    "                        obj : str = 'contacts', # ATMS object to retrieve\n",
    "                        initial_offset : int =0, # start retrieval at row initial_offset\n",
    "                        rows_per_batch :int =1000, # number records retrieved at once\n",
    "                        since_date : str = \"\", # if given, it will be used instead of `initial_offset` \n",
    "                        max_rows :int = 0 # maximum number of rows to retrieve\n",
    "                        ):\n",
    "    \"\"\"Retrieve data from ATMS API, clean data and write to file\"\"\"\n",
    "    self.write_obj_to_file(obj, initial_offset, rows_per_batch, since_date, max_rows)\n",
    "    self.clean_data_file(obj)\n",
    "    self.load_data_file_to_dict(obj)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `fetch_data_by_contactIds`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def fetch_data_by_contactIds(\n",
    "        self: ATMS_api,\n",
    "        obj_s : str = 'contacts', # string to describe object to fetch\n",
    "        id_l : list = [], # list of contactIds\n",
    "        store_data_b : bool = True # if True, store data in self.obj_d\n",
    "    ):\n",
    "    \"\"\" retrieve data from ATMS by contactId for a list of contactIds for the given object.\n",
    "        returns a list of dicts, one for each contactId\n",
    "    \"\"\"\n",
    "    l = []\n",
    "    # list unique\n",
    "    id_s = set(id_l)\n",
    "    for contact_id in id_s: #pelton_df.contactKey.unique():\n",
    "        print(\"fetch_data_by_contactIds :\", contact_id)\n",
    "        r = self.get_telus_data(obj_s, contact_id=contact_id)\n",
    "        try:\n",
    "            data_d = r['response'].json()\n",
    "            print(data_d)\n",
    "            l.append(data_d)\n",
    "        except Exception as e:\n",
    "            print(f\"choked on {r['response'].text}\")\n",
    "            raise e\n",
    "        sleep(1)\n",
    "    if store_data_b:\n",
    "        self.obj_d[obj_s] = l\n",
    "    return l ### write to obj_d ??"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `write_data_to_json_files `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@patch\n",
    "def write_data_to_json_files(self:ATMS_api):\n",
    "    \"\"\" write self.obj_d to json files in self.download_dir\"\"\"\n",
    "    # self.download_dir  = os.path.join(ATMS_api.class_download_dir, atms_id)\n",
    "    for obj_key, obj_v in self.obj_d.items():\n",
    "        first = True\n",
    "        with open(os.path.join(self.download_dir, f\"{obj_key}.json\"), 'w') as f:\n",
    "            for l in obj_v:\n",
    "                if first: \n",
    "                     f.write('[\\n')\n",
    "                     f.write(json.dumps(l))\n",
    "                     \n",
    "                     first = False\n",
    "                else:\n",
    "                      f.write(', \\n' + json.dumps(l) )\n",
    "            f.write(']\\n')\n",
    "            print(f\"File '{obj_key}.json' written successfully. to {self.download_dir}\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ``write_obj_d_to_file``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_obj_d_to_file(\n",
    "        self: ATMS_api,\n",
    "):\n",
    "    \"\"\" write the obj_d to file \"\"\"\n",
    "    for obj_s in self.obj_d:\n",
    "        self.write_obj_to_file(obj_s)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## write_obj_to_file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export    \n",
    "@patch\n",
    "def write_obj_to_file(self:ATMS_api, \n",
    "                        obj : str = 'contacts', # ATMS object to retrieve\n",
    "                        initial_offset : int =0, # start retrieval at row initial_offset\n",
    "                        rows_per_batch :int =1000, # number records retrieved at once\n",
    "                        since_date : str = \"\", # if given, it will be used instead of `initial_offset` \n",
    "                        max_rows :int = 0 # maximum number of rows to retrieve\n",
    "                        ):\n",
    "    \"\"\"Retrieve data from ATMS API and write to file\n",
    "        private method\n",
    "\n",
    "    Args:\n",
    "        obj (string): a valid ATMS REST API object\n",
    "        rows_per_batch (int, optional): maximum number of rows to retieve. Defaults to 1000.\n",
    "    \"\"\"\n",
    "    done = False\n",
    "    # offset is the starting row for the next batch\n",
    "    offset = initial_offset \n",
    "\n",
    "    filename_s = f'atms_{obj}.json'\n",
    "    print('download dir is: ', self.download_dir)\n",
    "    file_path_s = os.path.join(self.download_dir, filename_s)\n",
    "    # print(\"Writing to file: \", file_path_s)\n",
    "    \n",
    "    # if max_rows is 0, we'll retrieve all rows\n",
    "    with open(file_path_s, 'w') as f:\n",
    "        f.write(\"[ \\n\")\n",
    "        num_rows_for_next_batch = min(rows_per_batch, max_rows ) if max_rows > 0 else rows_per_batch\n",
    "\n",
    "        #max_remaining_rows will be decremented as we retrieve batches\n",
    "        max_remaining_rows = max_rows if max_rows > 0 else rows_per_batch\n",
    "\n",
    "        #num_rows_for_next_batch will be \n",
    "        num_rows_for_next_batch = min(rows_per_batch, max_remaining_rows) \n",
    "        first_line = True\n",
    "        while (not done and (num_rows_for_next_batch > 0)):\n",
    "\n",
    "            # read another batch\n",
    "            \n",
    "            print(f\"resp_d = self.get_telus_data({obj},offset={offset}, count= {num_rows_for_next_batch}, since_date={since_date})\")\n",
    "            resp_d = self.get_telus_data(obj,offset=offset, count= num_rows_for_next_batch, since_date=since_date)\n",
    "            print(\"resp_d.keys(): \", resp_d.keys())\n",
    "            if resp_d['response'].status_code != 200:\n",
    "                print(f\"Error retrieving data: {resp_d['response'].status_code}\")\n",
    "                print(f\"Error retrieving data: {resp_d['response'].json()}\")\n",
    "                raise ValueError(f\"Error retrieving data: {resp_d['response'].status_code}\")\n",
    "            obj_l = resp_d['response'].json()\n",
    "            done = resp_d['done'] ###### if done is set to True, we'll exit the loop\n",
    "            print(f\"done: {done}, resp_d.json() : {resp_d['response']}\")\n",
    "            \n",
    "            # assert len(obj_l)>0, f\"response: {resp_d}\"\n",
    "            try:\n",
    "                s = json.dumps(obj_l[0])\n",
    "            except:\n",
    "                print(\"Error converting to json: resp_d \", resp_d.json())\n",
    "                print(\"Error converting to json: obj_l \", obj_l)\n",
    "                raise ValueError(f\"Error converting to json {obj_l}\")\n",
    "            for o in obj_l[1:]:\n",
    "                try:\n",
    "                    s += ',\\n' +json.dumps(o) \n",
    "                except:\n",
    "                    print(\"Error converting to json: \", obj_l)\n",
    "                    raise ValueError(f\"Error converting to json {o}\")\n",
    "            # s = \",\\n\".join([json.dumps(o) for o in obj_l])\n",
    "            \n",
    "            if first_line:\n",
    "                f.write(s)\n",
    "                first_line = False\n",
    "            else:\n",
    "                f.write(\",\\n\"+s)\n",
    "            offset += rows_per_batch\n",
    "            max_remaining_rows = max_rows - (offset - initial_offset) if max_rows > 0 else rows_per_batch\n",
    "            num_rows_for_next_batch = min(rows_per_batch, max_remaining_rows)\n",
    "        f.write(\"\\n]\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## clean_data_file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def clean_data_file(self:ATMS_api, \n",
    "                    obj_s : str\n",
    "                    ): \n",
    "    \"\"\" Massage formatting to work with Salesfore Bulk API\n",
    "    \n",
    "    \"\"\"\n",
    "    # read original contacts file   \n",
    "    in_filename_s = f'atms_{obj_s}.json'\n",
    "    in_file_path_s = os.path.join(self.download_dir, in_filename_s)\n",
    "    print(\"cleaning_data_file - download dir is: \", self.download_dir)\n",
    "    # print(\"Cleaning file: \", in_file_path_s)\n",
    "    try:\n",
    "        with open(in_file_path_s,'r') as f:\n",
    "            # write modified contacts file \n",
    "            out_filename_s = f'atms_transformed_{obj_s}.json'\n",
    "            out_file_path_s = os.path.join(self.download_dir, out_filename_s)\n",
    "            print(\"creating file: \", out_file_path_s)\n",
    "            with open(out_file_path_s,'w') as f2:\n",
    "                s = f.read()\n",
    "                for l in s.split('\\n'):\n",
    "                    # remove \"O`Brien\" problem\n",
    "                    l2 = re.sub('\\u2019',\"'\",l)\n",
    "                    # fix emails\n",
    "                    new_s = ATMS_api._mutate_email_list(l2)+'\\n'\n",
    "                    f2.write(new_s)\n",
    "            print(f\"Finished cleaning {in_filename_s} -> {out_file_path_s}\")\n",
    "    except FileNotFoundError:\n",
    "        print('the files in our download dir:', os.listdir(self.download_dir) )\n",
    "        print('our in_file_path: ', in_file_path_s)\n",
    "            \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load_data_to_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def load_data_file_to_dict(\n",
    "        self:ATMS_api,\n",
    "        obj_s : str # ATMS object. eg. contacts|items|memberships|membership\n",
    "        ):\n",
    "        \"\"\" `load_data_file_to_dict` will attempt to load a cleaned json file into a dict for future parsing. \n",
    "        If the cleaned file doesn't exist, it will look for a dirty one to clean.\n",
    "        If the dirty once doesn't exist, it will raise an exception. It won't be downloaded because we don't know how much to get.\n",
    "        \n",
    "        \"\"\"\n",
    "        file_name_s = f'atms_transformed_{obj_s}.json'\n",
    "        file_path_s = os.path.join(self.download_dir, file_name_s)\n",
    "        print('ATMS_api - Attempting to load: ', file_path_s, ' into dict')\n",
    "        data=\"\"\n",
    "        try:\n",
    "            with open(file_path_s, 'r') as f:\n",
    "                data = f.read()\n",
    "        except FileNotFoundError:  # clean file not found\n",
    "            print(\"File not found. Check that the dirty file is there\")\n",
    "            dirty_file_name_s = f'atms_{obj_s}.json'\n",
    "            dirty_file_path_s = os.path.join(self.download_dir, dirty_file_name_s)\n",
    "\n",
    "            if os.path.exists(dirty_file_path_s):\n",
    "                print(f\"found dirty file: {dirty_file_path_s}\")\n",
    "                self.clean_data_file(obj_s)\n",
    "                with open(file_path_s,'r') as f:\n",
    "                    data = f.read()\n",
    "            else:\n",
    "                data = \"[]\"\n",
    "                print(\"in ATMS:load_data_file_to_dict. no dirty or clean file found. using empty dict\")\n",
    "                # raise FileNotFoundError # we give up\n",
    "        finally: # this will be executed regardless of first 'try' failing or not\n",
    "            if len(data) > 0:\n",
    "                try: # data might be buggy\n",
    "                    self.obj_d[obj_s] = json.loads(data)\n",
    "                    print(f\"ATMS_api: loaded {len(self.obj_d[obj_s])} {obj_s} into dict\")\n",
    "                except json.JSONDecodeError:\n",
    "                    print(\"We've got buggy data, or something\")\n",
    "                    raise Exception('Data is not JSON formatted')\n",
    "            # assert obj_s in self.obj_d, f\" '{obj_s}' not in {self.obj_d.keys()}\"\n",
    "\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Pick list for MembershipTerm.memberType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@patch \n",
    "def get_pick_list_for_MembeshipTerms_membershipType( self: ATMS_api):\n",
    "    \"\"\" utility func to get picklist values for 'membershipTyp'\n",
    "    this needs a full download to work\"\"\"\n",
    "    self.retrieve_and_clean('memberships')\n",
    "    print('\\n'.join(set(jp.search(\"[].membershipTerms[].membershipType\", self.obj_d['memberships']))))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# atms = ATMS_api()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pelton_ids = [ 4708, 119430, 119431, 144164,144165, 144166, 144167 ]\n",
    "# atms.fetch_data_by_contactIds('contacts', pelton_ids) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# atms.retrieve_and_clean('contacts', max_rows=1000, since_date='2020-01-01')\n",
    "# atms.retrieve_and_clean('memberships', max_rows=1000, since_date='2020-01-01')\n",
    "# atms.retrieve_and_clean('items', max_rows=1000, since_date='2020-01-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'playtime'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| export\n",
    "\n",
    "\"playtime\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory 'atms_download' already exists.\n",
      "Directory 'atms_upload' already exists.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/josephsmann/doubledot/blob/master/doubledot/ATMS_api.py#L87){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ATMS_api.delete_all_data\n",
       "\n",
       ">      ATMS_api.delete_all_data ()\n",
       "\n",
       "delete all the subdirectories and files in the download directory"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/josephsmann/doubledot/blob/master/doubledot/ATMS_api.py#L87){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ATMS_api.delete_all_data\n",
       "\n",
       ">      ATMS_api.delete_all_data ()\n",
       "\n",
       "delete all the subdirectories and files in the download directory"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(ATMS_api.delete_all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ATMS_api.delete_all_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/josephsmann/doubledot/blob/master/doubledot/ATMS_api.py#L227){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ATMS_api.get_telus_data\n",
       "\n",
       ">      ATMS_api.get_telus_data (obj:str, offset:int=0, since_date:str='',\n",
       ">                               count:int=1, contact_id:int=None)\n",
       "\n",
       "retrieve data from ATMS API, should be private method\n",
       "\n",
       "Args:\n",
       "    obj (string): api endpoint to retrieve data from\n",
       "    offset (int, optional): first row to begin retrieval. Defaults to 0.\n",
       "    count (int, optional): number of rows to retrieve. Defaults to 1000.\n",
       "\n",
       "Returns:\n",
       "    a dict with two keys: \"response\" and \"done\". \n",
       "    \"response\" is the response object from the API call. \"done\" is a boolean indicating whether there are more records to retrieve.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| obj | str |  | telus endpoint |\n",
       "| offset | int | 0 | the row to begin retrieval |\n",
       "| since_date | str |  | optionally, the date from which to retrieve |\n",
       "| count | int | 1 | the number of rows to retrieve |\n",
       "| contact_id | int | None | the contact id to retrieve |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/josephsmann/doubledot/blob/master/doubledot/ATMS_api.py#L227){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ATMS_api.get_telus_data\n",
       "\n",
       ">      ATMS_api.get_telus_data (obj:str, offset:int=0, since_date:str='',\n",
       ">                               count:int=1, contact_id:int=None)\n",
       "\n",
       "retrieve data from ATMS API, should be private method\n",
       "\n",
       "Args:\n",
       "    obj (string): api endpoint to retrieve data from\n",
       "    offset (int, optional): first row to begin retrieval. Defaults to 0.\n",
       "    count (int, optional): number of rows to retrieve. Defaults to 1000.\n",
       "\n",
       "Returns:\n",
       "    a dict with two keys: \"response\" and \"done\". \n",
       "    \"response\" is the response object from the API call. \"done\" is a boolean indicating whether there are more records to retrieve.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| obj | str |  | telus endpoint |\n",
       "| offset | int | 0 | the row to begin retrieval |\n",
       "| since_date | str |  | optionally, the date from which to retrieve |\n",
       "| count | int | 1 | the number of rows to retrieve |\n",
       "| contact_id | int | None | the contact id to retrieve |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(ATMS_api.get_telus_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/josephsmann/doubledot/blob/master/doubledot/ATMS_api.py#L344){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ATMS_api.write_obj_to_file\n",
       "\n",
       ">      ATMS_api.write_obj_to_file (obj:str='contacts', initial_offset:int=0,\n",
       ">                                  rows_per_batch:int=1000, since_date:str='',\n",
       ">                                  max_rows:int=0)\n",
       "\n",
       "Retrieve data from ATMS API and write to file\n",
       "    private method\n",
       "\n",
       "Args:\n",
       "    obj (string): a valid ATMS REST API object\n",
       "    rows_per_batch (int, optional): maximum number of rows to retieve. Defaults to 1000.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| obj | str | contacts | ATMS object to retrieve |\n",
       "| initial_offset | int | 0 | start retrieval at row initial_offset |\n",
       "| rows_per_batch | int | 1000 | number records retrieved at once |\n",
       "| since_date | str |  | if given, it will be used instead of `initial_offset` |\n",
       "| max_rows | int | 0 | maximum number of rows to retrieve |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/josephsmann/doubledot/blob/master/doubledot/ATMS_api.py#L344){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ATMS_api.write_obj_to_file\n",
       "\n",
       ">      ATMS_api.write_obj_to_file (obj:str='contacts', initial_offset:int=0,\n",
       ">                                  rows_per_batch:int=1000, since_date:str='',\n",
       ">                                  max_rows:int=0)\n",
       "\n",
       "Retrieve data from ATMS API and write to file\n",
       "    private method\n",
       "\n",
       "Args:\n",
       "    obj (string): a valid ATMS REST API object\n",
       "    rows_per_batch (int, optional): maximum number of rows to retieve. Defaults to 1000.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| obj | str | contacts | ATMS object to retrieve |\n",
       "| initial_offset | int | 0 | start retrieval at row initial_offset |\n",
       "| rows_per_batch | int | 1000 | number records retrieved at once |\n",
       "| since_date | str |  | if given, it will be used instead of `initial_offset` |\n",
       "| max_rows | int | 0 | maximum number of rows to retrieve |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(ATMS_api.write_obj_to_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/josephsmann/doubledot/blob/master/doubledot/ATMS_api.py#L203){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ATMS_api.list_files\n",
       "\n",
       ">      ATMS_api.list_files ()\n",
       "\n",
       "returns list of files in download folder"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/josephsmann/doubledot/blob/master/doubledot/ATMS_api.py#L203){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ATMS_api.list_files\n",
       "\n",
       ">      ATMS_api.list_files ()\n",
       "\n",
       "returns list of files in download folder"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(ATMS_api.list_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/josephsmann/doubledot/blob/master/doubledot/ATMS_api.py#L458){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ATMS_api.load_data_file_to_dict\n",
       "\n",
       ">      ATMS_api.load_data_file_to_dict (obj_s:str)\n",
       "\n",
       "`load_data_file_to_dict` will attempt to load a cleaned json file into a dict for future parsing. \n",
       "If the cleaned file doesn't exist, it will look for a dirty one to clean.\n",
       "If the dirty once doesn't exist, it will raise an exception. It won't be downloaded because we don't know how much to get.\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| obj_s | str | ATMS object. eg. contacts\\|items\\|memberships\\|membership |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/josephsmann/doubledot/blob/master/doubledot/ATMS_api.py#L458){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ATMS_api.load_data_file_to_dict\n",
       "\n",
       ">      ATMS_api.load_data_file_to_dict (obj_s:str)\n",
       "\n",
       "`load_data_file_to_dict` will attempt to load a cleaned json file into a dict for future parsing. \n",
       "If the cleaned file doesn't exist, it will look for a dirty one to clean.\n",
       "If the dirty once doesn't exist, it will raise an exception. It won't be downloaded because we don't know how much to get.\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| obj_s | str | ATMS object. eg. contacts\\|items\\|memberships\\|membership |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(ATMS_api.load_data_file_to_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/josephsmann/doubledot/blob/master/doubledot/ATMS_api.py#L423){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ATMS_api.clean_data_file\n",
       "\n",
       ">      ATMS_api.clean_data_file (obj_s:str)\n",
       "\n",
       "Massage formatting to work with Salesfore Bulk API"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/josephsmann/doubledot/blob/master/doubledot/ATMS_api.py#L423){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ATMS_api.clean_data_file\n",
       "\n",
       ">      ATMS_api.clean_data_file (obj_s:str)\n",
       "\n",
       "Massage formatting to work with Salesfore Bulk API"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(ATMS_api.clean_data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/josephsmann/doubledot/blob/master/doubledot/ATMS_api.py#L214){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ATMS_api.clean_data_dir\n",
       "\n",
       ">      ATMS_api.clean_data_dir (obj_s:str=None)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/josephsmann/doubledot/blob/master/doubledot/ATMS_api.py#L214){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ATMS_api.clean_data_dir\n",
       "\n",
       ">      ATMS_api.clean_data_dir (obj_s:str=None)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(ATMS_api.clean_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 105 column 7 (char 2245)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m#| hide\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnbdev\u001b[39;00m; nbdev\u001b[39m.\u001b[39mnbdev_export()\n",
      "File \u001b[0;32m~/anaconda3/envs/vantix/lib/python3.11/site-packages/fastcore/script.py:110\u001b[0m, in \u001b[0;36mcall_parse.<locals>._f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[39m@wraps\u001b[39m(func)\n\u001b[1;32m    108\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_f\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    109\u001b[0m     mod \u001b[39m=\u001b[39m inspect\u001b[39m.\u001b[39mgetmodule(inspect\u001b[39m.\u001b[39mcurrentframe()\u001b[39m.\u001b[39mf_back)\n\u001b[0;32m--> 110\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m mod: \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    111\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m SCRIPT_INFO\u001b[39m.\u001b[39mfunc \u001b[39mand\u001b[39;00m mod\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m==\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m\"\u001b[39m: SCRIPT_INFO\u001b[39m.\u001b[39mfunc \u001b[39m=\u001b[39m func\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\n\u001b[1;32m    112\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(sys\u001b[39m.\u001b[39margv)\u001b[39m>\u001b[39m\u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m sys\u001b[39m.\u001b[39margv[\u001b[39m1\u001b[39m]\u001b[39m==\u001b[39m\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m: sys\u001b[39m.\u001b[39margv\u001b[39m.\u001b[39mpop(\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/vantix/lib/python3.11/site-packages/nbdev/doclinks.py:138\u001b[0m, in \u001b[0;36mnbdev_export\u001b[0;34m(path, **kwargs)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39menviron\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mIN_TEST\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m0\u001b[39m): \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    137\u001b[0m files \u001b[39m=\u001b[39m nbglob(path\u001b[39m=\u001b[39mpath, as_path\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\u001b[39m.\u001b[39msorted(\u001b[39m'\u001b[39m\u001b[39mname\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 138\u001b[0m \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m files: nb_export(f)\n\u001b[1;32m    139\u001b[0m add_init(get_config()\u001b[39m.\u001b[39mlib_path)\n\u001b[1;32m    140\u001b[0m _build_modidx()\n",
      "File \u001b[0;32m~/anaconda3/envs/vantix/lib/python3.11/site-packages/nbdev/export.py:48\u001b[0m, in \u001b[0;36mnb_export\u001b[0;34m(nbname, lib_path, procs, debug, mod_maker, name)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[39mif\u001b[39;00m lib_path \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m: lib_path \u001b[39m=\u001b[39m get_config()\u001b[39m.\u001b[39mlib_path\n\u001b[1;32m     47\u001b[0m exp \u001b[39m=\u001b[39m ExportModuleProc()\n\u001b[0;32m---> 48\u001b[0m nb \u001b[39m=\u001b[39m NBProcessor(nbname, [exp]\u001b[39m+\u001b[39;49mL(procs), debug\u001b[39m=\u001b[39;49mdebug)\n\u001b[1;32m     49\u001b[0m nb\u001b[39m.\u001b[39mprocess()\n\u001b[1;32m     50\u001b[0m \u001b[39mfor\u001b[39;00m mod,cells \u001b[39min\u001b[39;00m exp\u001b[39m.\u001b[39mmodules\u001b[39m.\u001b[39mitems():\n",
      "File \u001b[0;32m~/anaconda3/envs/vantix/lib/python3.11/site-packages/nbdev/process.py:92\u001b[0m, in \u001b[0;36mNBProcessor.__init__\u001b[0;34m(self, path, procs, nb, debug, rm_directives, process)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, path\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, procs\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, nb\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, debug\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, rm_directives\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, process\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m---> 92\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnb \u001b[39m=\u001b[39m read_nb(path) \u001b[39mif\u001b[39;00m nb \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m nb\n\u001b[1;32m     93\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlang \u001b[39m=\u001b[39m nb_lang(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnb)\n\u001b[1;32m     94\u001b[0m     \u001b[39mfor\u001b[39;00m cell \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnb\u001b[39m.\u001b[39mcells: cell\u001b[39m.\u001b[39mdirectives_ \u001b[39m=\u001b[39m extract_directives(cell, remove\u001b[39m=\u001b[39mrm_directives, lang\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlang)\n",
      "File \u001b[0;32m~/anaconda3/envs/vantix/lib/python3.11/site-packages/execnb/nbio.py:57\u001b[0m, in \u001b[0;36mread_nb\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread_nb\u001b[39m(path):\n\u001b[1;32m     56\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mReturn notebook at `path`\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> 57\u001b[0m     res \u001b[39m=\u001b[39m dict2nb(_read_json(path, encoding\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m'\u001b[39;49m))\n\u001b[1;32m     58\u001b[0m     res[\u001b[39m'\u001b[39m\u001b[39mpath_\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(path)\n\u001b[1;32m     59\u001b[0m     \u001b[39mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/anaconda3/envs/vantix/lib/python3.11/site-packages/execnb/nbio.py:16\u001b[0m, in \u001b[0;36m_read_json\u001b[0;34m(self, encoding, errors)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_read_json\u001b[39m(\u001b[39mself\u001b[39m, encoding\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, errors\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m---> 16\u001b[0m     \u001b[39mreturn\u001b[39;00m loads(Path(\u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mread_text(encoding\u001b[39m=\u001b[39;49mencoding, errors\u001b[39m=\u001b[39;49merrors))\n",
      "File \u001b[0;32m~/anaconda3/envs/vantix/lib/python3.11/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    341\u001b[0m     s \u001b[39m=\u001b[39m s\u001b[39m.\u001b[39mdecode(detect_encoding(s), \u001b[39m'\u001b[39m\u001b[39msurrogatepass\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    343\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m object_hook \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m parse_float \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m object_pairs_hook \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_decoder\u001b[39m.\u001b[39;49mdecode(s)\n\u001b[1;32m    347\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    348\u001b[0m     \u001b[39mcls\u001b[39m \u001b[39m=\u001b[39m JSONDecoder\n",
      "File \u001b[0;32m~/anaconda3/envs/vantix/lib/python3.11/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecode\u001b[39m(\u001b[39mself\u001b[39m, s, _w\u001b[39m=\u001b[39mWHITESPACE\u001b[39m.\u001b[39mmatch):\n\u001b[1;32m    333\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[39m    containing a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m     obj, end \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mraw_decode(s, idx\u001b[39m=\u001b[39;49m_w(s, \u001b[39m0\u001b[39;49m)\u001b[39m.\u001b[39;49mend())\n\u001b[1;32m    338\u001b[0m     end \u001b[39m=\u001b[39m _w(s, end)\u001b[39m.\u001b[39mend()\n\u001b[1;32m    339\u001b[0m     \u001b[39mif\u001b[39;00m end \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(s):\n",
      "File \u001b[0;32m~/anaconda3/envs/vantix/lib/python3.11/json/decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    353\u001b[0m     obj, end \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscan_once(s, idx)\n\u001b[1;32m    354\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m--> 355\u001b[0m     \u001b[39mraise\u001b[39;00m JSONDecodeError(\u001b[39m\"\u001b[39m\u001b[39mExpecting value\u001b[39m\u001b[39m\"\u001b[39m, s, err\u001b[39m.\u001b[39mvalue) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \u001b[39mreturn\u001b[39;00m obj, end\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 105 column 7 (char 2245)"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
