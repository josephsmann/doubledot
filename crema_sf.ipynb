{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# doubledot.Salesforce\n",
    "> Salesforce class for transfering data from Vantix to Salesforce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp crema_sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti \n",
    "import io\n",
    "from nbdev.showdoc import *\n",
    "import requests\n",
    "import json\n",
    "import jmespath as jp\n",
    "import re\n",
    "from time import sleep\n",
    "from fastcore.basics import patch\n",
    "import fileinput\n",
    "import pandas as pd\n",
    "import os\n",
    "from doubledot import ATMS_api\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/josephsmann/doubledot/blob/master/doubledot/crema_sf.py#L65){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Salesforce.sf_access_token\n",
       "\n",
       ">      Salesforce.sf_access_token ()\n",
       "\n",
       "a @property\n",
       "retrieve token for Salesforce - verifies that token is still valid and attempts to get a new one from Salesforce site if not"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/josephsmann/doubledot/blob/master/doubledot/crema_sf.py#L65){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Salesforce.sf_access_token\n",
       "\n",
       ">      Salesforce.sf_access_token ()\n",
       "\n",
       "a @property\n",
       "retrieve token for Salesforce - verifies that token is still valid and attempts to get a new one from Salesforce site if not"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| export\n",
    "## Module for Salesforce API\n",
    "\n",
    "class Salesforce:\n",
    "    \"\"\"Class for Salesforce API\"\"\"\n",
    "    class_download_dir = os.path.join(os.getcwd(),'sf_download')\n",
    "\n",
    "    def __init__(self):\n",
    "        # set up access token \n",
    "        self._sf_access_token = self.get_token_with_REST()\n",
    "        self.bulk_job_id = None\n",
    "        self.atms = None\n",
    "\n",
    "        # create unique download directory per instance\n",
    "        if not os.path.exists(Salesforce.class_download_dir):\n",
    "            os.makedirs(Salesforce.class_download_dir)\n",
    "            print(f\"Directory 'atms_download' created successfully.\")\n",
    "        else:\n",
    "            print(f\"Directory 'atms_download' already exists.\")\n",
    "\n",
    "    def get_token_with_REST(self ):\n",
    "        \"\"\"retieve the access token from Salesforce\n",
    "\n",
    "        Returns:\n",
    "            string: the access token \n",
    "        \"\"\"\n",
    "        with open('secrets.json') as f:\n",
    "            secrets = json.load(f)\n",
    "        \n",
    "        DOMAIN = secrets['instance']\n",
    "        payload = {\n",
    "            'grant_type': 'password',\n",
    "            'client_id': secrets['client_id'],\n",
    "            'client_secret': secrets['client_secret'],\n",
    "            'username': secrets['username'],\n",
    "            'password': secrets['password'] + secrets['security_token']\n",
    "        }\n",
    "        oauth_url = f'{DOMAIN}/services/oauth2/token'\n",
    "\n",
    "        auth_response = requests.post(oauth_url, data=payload)\n",
    "        return auth_response.json().get('access_token') ######## <<<<<<<<<<<<<<<< .       \n",
    "\n",
    "\n",
    "    @property\n",
    "    def sf_access_token(\n",
    "        self \n",
    "     ) -> str : #the access toke\n",
    "        \"\"\"a @property\n",
    "        retrieve token for Salesforce - verifies that token is still valid and attempts to get a new one from Salesforce site if not\n",
    "        \"\"\"\n",
    "        if not(self.test_token()):\n",
    "            self._sf_access_token = self.get_token_with_REST()\n",
    "            # check to see if getting token worked\n",
    "            assert (self.sf_access_token), \"Fetching new token didn't fix problem\"\n",
    "        return self._sf_access_token\n",
    "    \n",
    "    @staticmethod\n",
    "    def list_files():\n",
    "        return os.listdir(Salesforce.class_download_dir)\n",
    "\n",
    "show_doc(Salesforce.sf_access_token)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def get_token_with_REST(self: Salesforce):\n",
    "    \"\"\"retieve the access token from Salesforce\n",
    "\n",
    "    Returns:\n",
    "        string: the access token \n",
    "    \"\"\"\n",
    "    with open('secrets.json') as f:\n",
    "        secrets = json.load(f)\n",
    "    \n",
    "    DOMAIN = secrets['instance']\n",
    "    payload = {\n",
    "        'grant_type': 'password',\n",
    "        'client_id': secrets['client_id'],\n",
    "        'client_secret': secrets['client_secret'],\n",
    "        'username': secrets['username'],\n",
    "        'password': secrets['password'] + secrets['security_token']\n",
    "    }\n",
    "    oauth_url = f'{DOMAIN}/services/oauth2/token'\n",
    "\n",
    "    auth_response = requests.post(oauth_url, data=payload)\n",
    "    return auth_response.json().get('access_token') ######## <<<<<<<<<<<<<<<< .       \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def test_token(self: Salesforce):\n",
    "    \"\"\"Verify that token is still valid. If it isn't, it attempts to get a new one.\n",
    "\n",
    "    Returns:\n",
    "        boolean: true if token is valid, false otherwise\n",
    "    \"\"\"\n",
    "    sf_headers = { 'Authorization': f\"Bearer {self._sf_access_token}\", 'Content-Type': 'application/json' }\n",
    "    end_point =\"https://cremaconsulting-dev-ed.develop.my.salesforce.com\"\n",
    "    service = \"/services/data/v57.0/\"\n",
    "    r = requests.request(\"GET\", end_point+service+f\"limits\", headers=sf_headers, data={})\n",
    "    valid_token = r.status_code == 200\n",
    "    if not(valid_token): print(r.status_code, type(r.status_code))\n",
    "    return valid_token\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def create_job(self: Salesforce, \n",
    "                sf_object: str ='Contact', # the Salesforce object were going to operate on. \n",
    "                operation: str ='insert', # the database operation to use. Can be \"insert\",\"upsert\" or \"delete\"\n",
    "                external_id: str = 'External_Id__c' # when using \"upsert\", this field is used to identify the record\n",
    "                )-> requests.Response :\n",
    "    \"\"\"Get job_id from Salesforce Bulk API\n",
    "\n",
    "    \"\"\"\n",
    "    # Args: \n",
    "    #     sf_object (str, optional): the Salesforce object were going to operate on. Defaults to 'Contact'.\n",
    "    #     operation (str, optional): âˆ†. Defaults to 'insert'.\n",
    "    #     external_id (str, optional): the external id field for upsert operations. Defaults to 'External_Id__c'.\n",
    "    #     sf_object (str, optional): the Salesforce object were going to operate on. Defaults to 'Contact'.\n",
    "    #     operation (str, optional): the operation that will be used against the object. Defaults to 'insert'.\n",
    "    #     external_id (str, optional): the external id field for upsert operations. Defaults to 'External_Id__c'.\n",
    "    #     contentType (str, optional): the content type of the file. Defaults to 'CSV', 'JSON' also accepted.\n",
    "    # Returns: \n",
    "    #     response: a response object containg the job_id. For more information on the response object see https://www.w3schools.com/python/ref_requests_response.asp\n",
    "    #     a response object see https://www.w3schools.com/python/ref_requests_response.asp\n",
    "        \n",
    "    # Salesforce API docs: https://developer.salesforce.com/docs/atlas.en-us.api_asynch.meta/api_asynch/create_job.htm    \n",
    "    url = \"https://cremaconsulting-dev-ed.develop.my.salesforce.com/services/data/v57.0/jobs/ingest\"\n",
    "\n",
    "    # https://developer.salesforce.com/docs/atlas.en-us.api_asynch.meta/api_asynch/datafiles_prepare_csv.htm\n",
    "    ## we can set columnDelimiter to `,^,|,;,<tab>, and the default <comma>\n",
    "    # sets the object to Contact, the content type to CSV, and the operation to insert\n",
    "    payload_d = {\n",
    "        \"object\": sf_object,\n",
    "        \"contentType\": \"CSV\",\n",
    "        # set columnDelimiter to TAB instead of comma for ease of dealing with commas in address fields\n",
    "        #https://developer.salesforce.com/docs/atlas.en-us.api_asynch.meta/api_asynch/create_job.htm\n",
    "        \"columnDelimiter\": \"TAB\", \n",
    "        \"operation\": operation\n",
    "    }\n",
    "    \n",
    "    # as per https://developer.salesforce.com/docs/atlas.en-us.api_asynch.meta/api_asynch/walkthrough_upsert.htm\n",
    "    if operation=='upsert':\n",
    "        payload_d['externalIdFieldName']=external_id\n",
    "    payload = json.dumps(payload_d)\n",
    "    \n",
    "    headers = {\n",
    "    'Content-Type': 'application/json',\n",
    "    'Authorization': f'Bearer {self.sf_access_token}'\n",
    "    }\n",
    "\n",
    "    response = requests.request(\"POST\", url, headers=headers, data=payload)\n",
    "    # print(response.text)\n",
    "    try:\n",
    "        self.bulk_job_id = response.json()['id']\n",
    "    except TypeError:\n",
    "        print(\"Bad response in Salesforce.create_job :\\n\", response.text)\n",
    "        \n",
    "    print(f\"Created job {self.bulk_job_id} for {sf_object} with operation {operation}\") \n",
    "    return response \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def upload_csv(self : Salesforce, \n",
    "                obj_s: str = \"\", # Salesforce object to upload \n",
    "                # num_rows: int = 100, # the number of rows to upload \n",
    "                ) -> requests.Response:\n",
    "    \"\"\"Using the job_id from the previous step, upload the csv file to the job\n",
    "\n",
    "    Args:\n",
    "        file (filepointer): file pointer to the csv filek\n",
    "    \"\"\"\n",
    "    # if not(file):\n",
    "    #     # throw error\n",
    "    #     assert False, \"File not found\"\n",
    "\n",
    "\n",
    "    assert obj_s in ['Contact', 'Membership__c', 'MembershipTerm__c', 'MembershipMember__c']\n",
    "\n",
    "    print(f\"Uploading job {self.bulk_job_id} of object {obj_s}\")\n",
    "\n",
    "    file_path_s = os.path.join(Salesforce.class_download_dir , f\"{obj_s}.csv\")\n",
    "\n",
    "    url = f\"https://cremaconsulting-dev-ed.develop.my.salesforce.com/services/data/v57.0/jobs/ingest/{self.bulk_job_id}/batches\"\n",
    "\n",
    "    # replace all occurrences of '\\2019' with \\'\n",
    "    # we may have done this in ATMS already, but just in case\n",
    "    try:\n",
    "        for line in fileinput.input(files=file_path_s, inplace=True):\n",
    "            line = line.replace('\\u2019', \"'\")\n",
    "            print(line, end='') # this prints to the file instead of stdout (!!)\n",
    "\n",
    "        with open(file_path_s,'r') as payload:\n",
    "            headers = {\n",
    "                'Content-Type': 'text/csv',\n",
    "                'Authorization': f'Bearer {self.sf_access_token}'\n",
    "                }\n",
    "            response = requests.request(\"PUT\", url, headers=headers, data=payload)\n",
    "    except FileNotFoundError:\n",
    "        print(\"File not found error in Saleforce.upload_csv: \", file_path_s)\n",
    "        return None\n",
    "    \n",
    "    return response\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "@patch\n",
    "def close_job(self: Salesforce):\n",
    "    # close the job (from Postman)\n",
    "    url = f\"https://cremaconsulting-dev-ed.develop.my.salesforce.com/services/data/v57.0/jobs/ingest/{self.bulk_job_id}\"\n",
    "\n",
    "    payload = json.dumps({\n",
    "        \"state\": \"UploadComplete\"\n",
    "    })\n",
    "    headers = {\n",
    "    'Content-Type': 'application/json',\n",
    "    'Authorization': f'Bearer {self.sf_access_token}'\n",
    "    }\n",
    "\n",
    "    response = requests.request(\"PATCH\", url, headers=headers, data=payload)\n",
    "\n",
    "    # print(response.text)\n",
    "    return response.json()\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export       \n",
    "# get job status (from Postman)\n",
    "@patch\n",
    "def job_status(self: Salesforce):\n",
    "    url = f\"https://cremaconsulting-dev-ed.develop.my.salesforce.com/services/data/v57.0/jobs/ingest/{self.bulk_job_id}\"\n",
    "\n",
    "    payload = {}\n",
    "    headers = {\n",
    "    'Authorization': f'Bearer {self.sf_access_token}'\n",
    "    }\n",
    "    response = requests.request(\"GET\", url, headers=headers, data=payload)\n",
    "    return response.json()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def successful_results(self : Salesforce):\n",
    "    url = f\"https://cremaconsulting-dev-ed.develop.my.salesforce.com/services/data/v57.0/jobs/ingest/{self.bulk_job_id}/successfulResults\"\n",
    "\n",
    "    payload = {}\n",
    "    headers = {\n",
    "        'Authorization': f'Bearer {self.sf_access_token}'\n",
    "    }\n",
    "\n",
    "    response = requests.request(\"GET\", url, headers=headers, data=payload)\n",
    "    \n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def failed_results(self: Salesforce):\n",
    "    url = f\"https://cremaconsulting-dev-ed.develop.my.salesforce.com/services/data/v57.0/jobs/ingest/{self.bulk_job_id}/failedResults\"\n",
    "\n",
    "    payload = {}\n",
    "    headers = {\n",
    "        'Authorization': f'Bearer {self.sf_access_token}'\n",
    "    }\n",
    "\n",
    "    response = requests.request(\"GET\", url, headers=headers, data=payload)\n",
    "\n",
    "    # \n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def get_sf_object_ids(self: Salesforce, \n",
    "                      object: str = 'Contact' # REST endpoint for data object\n",
    "                      ):\n",
    "    \"\"\"Get Safesforce IDs for a the specified object\n",
    "\n",
    "    \"\"\"\n",
    "    print(f\"Retrieving Object Ids for {object} from Salesforce\")\n",
    "    sf_headers = { 'Authorization': f\"Bearer {self.sf_access_token}\", 'Content-Type': 'application/json' }\n",
    "    end_point =\"https://cremaconsulting-dev-ed.develop.my.salesforce.com\"\n",
    "    service = \"/services/data/v57.0/\"\n",
    "    r = requests.request(\"GET\", end_point+service+f\"query/?q=SELECT+Id+FROM+{object}\", headers=sf_headers, data={})\n",
    "    assert isinstance(r.json(), dict), f\"response: {r.json()}, header: {sf_headers}\"\n",
    "    object_ids = [d.get('Id') for d in r.json()['records']]\n",
    "    while r.json()['done'] == False:\n",
    "        new_url = end_point+r.json()['nextRecordsUrl']\n",
    "        print(new_url)\n",
    "        r = requests.request(\"GET\", new_url, headers=sf_headers, data={})\n",
    "        print((r.json()))\n",
    "        fresh_object_ids = [d.get('Id') for d in r.json()['records']]\n",
    "        print(len(fresh_object_ids))   \n",
    "        object_ids+=fresh_object_ids\n",
    "        \n",
    "    print('total number of objects = ',len(object_ids))\n",
    "    return object_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def delete_sf_objects(self: Salesforce, \n",
    "                      obj_s: str = 'Contact'\n",
    "                      ):\n",
    "    \"\"\"Delete Salesforce objects\"\"\"\n",
    "    print(f\"Deleting {obj_s} objects from Salesforce\")\n",
    "    object_ids = self.get_sf_object_ids(obj_s)\n",
    "    file_path_s = os.path.join(Salesforce.class_download_dir , f\"{obj_s}.csv\")\n",
    "    print(f\"In Salesforce.delete_sf_objects: Deleting {len(object_ids)} {obj_s} objects using {file_path_s}\")\n",
    "    with open(file_path_s, 'w') as f:\n",
    "        f.write('Id\\n')\n",
    "        for id in object_ids:\n",
    "            f.write(id+'\\n')\n",
    "            \n",
    "    # force execute_job to use the csv file we just created        \n",
    "    self.execute_job(obj_s, 'delete', use_ATMS_data=False)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def test_sf_object_load_and_delete(self: Salesforce, \n",
    "        sf_object_s : str = None, # Salesforce API endpoint\n",
    "        input_file_s: str = None, # local file name\n",
    "        remove_sf_objs: bool = False # remove the data just added to Salesforce\n",
    "        ):\n",
    "    \"\"\"Test loading a Salesforce object with data from a local file\"\"\"\n",
    "    assert sf_object_s\n",
    "    assert input_file_s\n",
    "\n",
    "    # sf.create_job('MembershipMembers__c', contentType='CSV')\n",
    "    self.create_job(sf_object_s, contentType='CSV')\n",
    "    print(\"Salesforce job id: \", self.bulk_job_id)\n",
    "\n",
    "    #replace \n",
    "    # culprit is \\u2019 - it cannot be encoded in latin-1 codec\n",
    "    self.upload_csv(input_file_s)\n",
    "    \n",
    "        \n",
    "\n",
    "    self.close_job()\n",
    "    self.failed_results()\n",
    "    self.successful_results()\n",
    "    self.job_status()\n",
    "\n",
    "    if remove_sf_objs:\n",
    "        self.delete_sf_objects('membershipTerm__c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "\n",
    "mem_s = \"[].{membershipId__c: membershipId, \\\n",
    "    memberSince__c: memberSince, \\\n",
    "    updateDate__c: updateDate}\"\n",
    "\n",
    "memTerm_s = \"[].membershipTerms[].{membershipTermId__c: membershipTermId,\\\n",
    "membershipKey__r_1_membershipId__c:membershipKey,\\\n",
    "effectiveDate__c:effectiveDate,\\\n",
    "expiryDate__c:expiryDate,\\\n",
    "membershipType__c:membershipType,\\\n",
    "upgradeFromTermKey__c:upgradeFromTermKey,\\\n",
    "giftMembership__c:giftMembership,\\\n",
    "refunded__c:refunded,\\\n",
    "saleDetailKey__c:saleDetailKey,\\\n",
    "itemKey__c:itemKey}\"\n",
    "\n",
    "memMembers_s = \"[].membershipTerms[].membershipMembers[].{membershipMemberId__c:membershipMemberId,\\\n",
    "membershipTermKey__r_1_membershipTermId__c:membershipTermKey,\\\n",
    "cardNumber__c:cardNumber,\\\n",
    "membershipNumber__c:membershipNumber,\\\n",
    "cardStatus__c:cardStatus,\\\n",
    "contactKey__c:contactKey,\\\n",
    "displayName__c:displayName}\"\n",
    "\n",
    "@patch\n",
    "def process_memberships(self: Salesforce ):\n",
    "    \"\"\"Unpack memberships data from atms object and write to membership, membership_terms, and membership_members csv files.\n",
    "    \n",
    "    We could modify this function to only process one of Memmbership, MembershipTerm, or MembershipMember.\n",
    "    \"\"\"\n",
    "    print(\"Processing memberships data\")\n",
    "    # custom objects need '__c' suffix\n",
    "    mem_d = { 'memberships': {'fname':'Membership__c.csv', 'jmespath': mem_s},\n",
    "               'membership_terms': {'fname':'MembershipTerm__c.csv','jmespath': memTerm_s},\n",
    "               'membership_members': {'fname': 'MembershipMember__c.csv', 'jmespath': memMembers_s}\n",
    "                }\n",
    "            \n",
    "\n",
    "    if not ('memberships' in self.atms.obj_d):\n",
    "        self.atms.load_data_file_to_dict('memberships')\n",
    "        assert 'memberships' in self.atms.obj_d, f\"memberships not in atms.obj_d {self.atms.obj_d.keys()}\"\n",
    "    \n",
    "    atms_d = self.atms.obj_d['memberships']\n",
    "\n",
    "    for key, v_pair in mem_d.items():\n",
    "        file_path_s = os.path.join(Salesforce.class_download_dir, v_pair['fname'])\n",
    "        dict_l = jp.search(v_pair['jmespath'], atms_d)\n",
    "        print(f\"Salesforce: Writing {len(dict_l)} {key} objects to {file_path_s}\")\n",
    "        with open(file_path_s, 'w') as f:\n",
    "            if len(dict_l) == 0:\n",
    "                print(f\"Warning: no {key} objects found\")\n",
    "                continue\n",
    "            # hack to create header with a dot in it, jmespath won't do it\n",
    "            f.write('\\t'.join([s.replace('_1_','.') for s in dict_l[0].keys()]) + '\\n') # header\n",
    "            for d in dict_l:\n",
    "                #changed this to not write None for empty values, eg \"\" for null and false (a default value)\n",
    "                f.write('\\t'.join([str(v) if v else \"\" for v in d.values()]) + '\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "search_s = \"[].{LastName: organizationName,\\\n",
    "    MailingPostalCode: addresses[0].postalZipCode,\\\n",
    "    MailingCity: addresses[0].city,\\\n",
    "    MailingStreet: addresses[0].line1, \\\n",
    "    MailingCountry: addresses[0].country, \\\n",
    "    Phone: phones[?phoneType == 'Business'].phoneNumber | [0],\\\n",
    "    Email: emails[0].address[0],\\\n",
    "    External_Id__c: contactId}\"\n",
    "\n",
    "import re\n",
    "\n",
    "def escape_quotes(text):\n",
    "    # Escape single quotes\n",
    "    # text = re.sub(r\"\\'\", r\"\\\\'\", text)\n",
    "    text = re.sub(r\"\\'\", r\"_\", text)\n",
    "    # Escape double quotes\n",
    "    text = re.sub(r'\\\"', r'_', text)\n",
    "    # text = re.sub(r',', r'*', text) ## shouldn't be necessary with tab delimiter\n",
    "    # text = re.sub(r'\\\"', r'\\\\\"', text)\n",
    "    return text.strip()\n",
    "\n",
    "@patch\n",
    "def process_contacts(self: Salesforce ):\n",
    "    \"\"\" unpack contacts data from atms object and write to contacts csv file.\"\"\"\n",
    "    print(\"process_contacts\")\n",
    "    if not ('contacts' in self.atms.obj_d):\n",
    "        self.atms.load_data_file_to_dict('contacts')\n",
    "        assert 'contacts' in self.atms.obj_d, f\"contacts not in atms.obj_d {self.atms.obj_d.keys()}\"\n",
    "    \n",
    "    file_path_s = os.path.join(Salesforce.class_download_dir, 'Contact.csv')\n",
    "    dict_l = jp.search(search_s, self.atms.obj_d['contacts'])\n",
    "\n",
    "    # if contact record has no LastName then\n",
    "    for r in dict_l:\n",
    "        if r['LastName'] == None:\n",
    "            r['LastName'] = 'Not Provided'\n",
    "\n",
    "    print(f\"Salesforce: Writing {len(dict_l)} 'Contact' objects to {file_path_s}\")\n",
    "    columnDelimiter = '\\t'\n",
    "    with open(file_path_s, 'w') as f:\n",
    "        header = columnDelimiter.join(dict_l[0].keys())\n",
    "        f.write(header+'\\n')\n",
    "        for item in dict_l:\n",
    "            l = [escape_quotes(str(v)) if v else \" \" for v in item.values()]\n",
    "            f.write(columnDelimiter.join(l)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@patch\n",
    "def execute_job(self: Salesforce, \n",
    "        sf_object_s : str = None, # Salesforce API object name\n",
    "        operation : str = None, # REST operation, e.g. insert, upsert, delete\n",
    "        max_trys : int = 20, # max number of times to try to get job status\n",
    "        external_id : str = 'External_Id__c', # name of the field that is the unique identifier to ATMS\n",
    "        use_ATMS_data : bool = True, # if True, use data from ATMS object, otherwise use data from local file\n",
    "        # **kwargs : dict # additional parameters to pass to the REST API\n",
    "        ):\n",
    "    \"\"\"Test loading a Salesforce object with data from a local file\"\"\"\n",
    "    print(\"execute_job\")\n",
    "    if sf_object_s not in ['Contact', 'Membership__c', 'MembershipTerm__c', 'MembershipMember__c']:\n",
    "        print(\"sf_object_s must be one of Contact, Membership__c, MembershipTerm__c, MembershipMember__c\")\n",
    "        return\n",
    "    \n",
    "    if operation not in ['insert', 'upsert', 'delete']:\n",
    "        print(\"operation must be one of insert, update, delete\")\n",
    "        return\n",
    "    \n",
    "    if sf_object_s == 'Contact' and use_ATMS_data:\n",
    "        # this creates a file Contact.csv in the class_download_dir\n",
    "        self.process_contacts()\n",
    "    \n",
    "    if sf_object_s in ['Membership__c', 'MembershipMember__c', 'MembershipTerm__c'] and use_ATMS_data:\n",
    "        # this creates files Membership__c.csv, MembershipMember__c.csv, MembershipTerm__c.csv in the class_download_dir\n",
    "        self.process_memberships()\n",
    "     \n",
    "    self.create_job(sf_object=sf_object_s, operation=operation, external_id=external_id)\n",
    "    self.upload_csv(sf_object_s)\n",
    "    self.close_job()\n",
    "\n",
    "    counter = 0\n",
    "    sleep_time = 3\n",
    "    \n",
    "    print(\"job status:\", self.job_status()['state'])\n",
    "    while self.job_status()['state']!='JobComplete' and counter < max_trys:\n",
    "        print(f\"waiting for job to complete, try {counter}, status: {self.job_status()['state']}\")\n",
    "        counter += 1\n",
    "        time.sleep(sleep_time)\n",
    "\n",
    "    print(\"Failed results:\")\n",
    "    print(self.failed_results().text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory 'atms_download' already exists.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'00D8Y000001RMKv!AQwAQCSJnFU8nTvr71TNBx5yRl0HQeOnQLMiz2aXllJr39Do3FZb7aLECeQp6piixytROoY1V8DFlSo3OSHtiQBpal.uZ1Kx'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sf = Salesforce()\n",
    "sf._sf_access_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# atms = ATMS_api()\n",
    "# atms.delete_all_data() \n",
    "# sf.delete_sf_objects('Contact')\n",
    "# sf.delete_sf_objects('Membership__c')\n",
    "# sf.delete_sf_objects('MembershipTerm__c')\n",
    "# sf.delete_sf_objects('MembershipMember__c')\n",
    "\n",
    "# atms = ATMS_api()\n",
    "# sf.atms = atms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sf.delete_sf_objects('Contact')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# atms.retrieve_and_clean('memberships', since_date='2020-01-01', max_rows=200)\n",
    "# atms.retrieve_and_clean('contacts', since_date='2020-01-01', max_rows=200)\n",
    "# atms.retrieve_and_clean('items', since_date='2020-01-01', max_rows=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sf.execute_job(sf_object_s='MembershipMember__c', operation='upsert', external_id='membershipMemberId__c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(failed_response.text)\n",
    "# pd.read_csv(io.StringIO(failed_response.text), sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vantix",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
