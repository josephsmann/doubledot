{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# doubledot.Salesforce\n",
    "> Salesforce class for transfering data from Vantix to Salesforce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp crema_sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti \n",
    "from nbdev.showdoc import *\n",
    "import requests\n",
    "import json\n",
    "import jmespath as jp\n",
    "import re\n",
    "from time import sleep\n",
    "from fastcore.basics import patch\n",
    "import fileinput\n",
    "import pandas as pd\n",
    "import os\n",
    "from doubledot import ATMS_api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/josephsmann/doubledot/blob/master/doubledot/crema_sf.py#L63){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Salesforce.sf_access_token\n",
       "\n",
       ">      Salesforce.sf_access_token ()\n",
       "\n",
       "a @property\n",
       "retrieve token for Salesforce - verifies that token is still valid and attempts to get a new one from Salesforce site if not"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/josephsmann/doubledot/blob/master/doubledot/crema_sf.py#L63){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Salesforce.sf_access_token\n",
       "\n",
       ">      Salesforce.sf_access_token ()\n",
       "\n",
       "a @property\n",
       "retrieve token for Salesforce - verifies that token is still valid and attempts to get a new one from Salesforce site if not"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| export\n",
    "## Module for Salesforce API\n",
    "\n",
    "class Salesforce:\n",
    "    \"\"\"Class for Salesforce API\"\"\"\n",
    "    class_download_dir = 'sf_download'\n",
    "\n",
    "    def __init__(self):\n",
    "        # set up access token \n",
    "        self._sf_access_token = self.get_token_with_REST()\n",
    "        self.bulk_job_id = None\n",
    "        self.atms = None\n",
    "\n",
    "        # create unique download directory per instance\n",
    "        if not os.path.exists(Salesforce.class_download_dir):\n",
    "            os.makedirs(Salesforce.class_download_dir)\n",
    "            print(f\"Directory 'atms_download' created successfully.\")\n",
    "        else:\n",
    "            print(f\"Directory 'atms_download' already exists.\")\n",
    "\n",
    "    def get_token_with_REST(self ):\n",
    "        \"\"\"retieve the access token from Salesforce\n",
    "\n",
    "        Returns:\n",
    "            string: the access token \n",
    "        \"\"\"\n",
    "        with open('secrets.json') as f:\n",
    "            secrets = json.load(f)\n",
    "        \n",
    "        DOMAIN = secrets['instance']\n",
    "        payload = {\n",
    "            'grant_type': 'password',\n",
    "            'client_id': secrets['client_id'],\n",
    "            'client_secret': secrets['client_secret'],\n",
    "            'username': secrets['username'],\n",
    "            'password': secrets['password'] + secrets['security_token']\n",
    "        }\n",
    "        oauth_url = f'{DOMAIN}/services/oauth2/token'\n",
    "\n",
    "        auth_response = requests.post(oauth_url, data=payload)\n",
    "        return auth_response.json().get('access_token') ######## <<<<<<<<<<<<<<<< .       \n",
    "\n",
    "\n",
    "    @property\n",
    "    def sf_access_token(\n",
    "        self \n",
    "     ) -> str : #the access toke\n",
    "        \"\"\"a @property\n",
    "        retrieve token for Salesforce - verifies that token is still valid and attempts to get a new one from Salesforce site if not\n",
    "        \"\"\"\n",
    "        if not(self.test_token()):\n",
    "            self._sf_access_token = self.get_token_with_REST()\n",
    "            # check to see if getting token worked\n",
    "            assert (self.sf_access_token), \"Fetching new token didn't fix problem\"\n",
    "        return self._sf_access_token\n",
    "    \n",
    "    @staticmethod\n",
    "    def list_files():\n",
    "        return os.listdir(Salesforce.class_download_dir)\n",
    "\n",
    "show_doc(Salesforce.sf_access_token)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def get_token_with_REST(self: Salesforce):\n",
    "    \"\"\"retieve the access token from Salesforce\n",
    "\n",
    "    Returns:\n",
    "        string: the access token \n",
    "    \"\"\"\n",
    "    with open('secrets.json') as f:\n",
    "        secrets = json.load(f)\n",
    "    \n",
    "    DOMAIN = secrets['instance']\n",
    "    payload = {\n",
    "        'grant_type': 'password',\n",
    "        'client_id': secrets['client_id'],\n",
    "        'client_secret': secrets['client_secret'],\n",
    "        'username': secrets['username'],\n",
    "        'password': secrets['password'] + secrets['security_token']\n",
    "    }\n",
    "    oauth_url = f'{DOMAIN}/services/oauth2/token'\n",
    "\n",
    "    auth_response = requests.post(oauth_url, data=payload)\n",
    "    return auth_response.json().get('access_token') ######## <<<<<<<<<<<<<<<< .       \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def test_token(self: Salesforce):\n",
    "    \"\"\"Verify that token is still valid. If it isn't, it attempts to get a new one.\n",
    "\n",
    "    Returns:\n",
    "        boolean: true if token is valid, false otherwise\n",
    "    \"\"\"\n",
    "    sf_headers = { 'Authorization': f\"Bearer {self._sf_access_token}\", 'Content-Type': 'application/json' }\n",
    "    end_point =\"https://cremaconsulting-dev-ed.develop.my.salesforce.com\"\n",
    "    service = \"/services/data/v57.0/\"\n",
    "    r = requests.request(\"GET\", end_point+service+f\"limits\", headers=sf_headers, data={})\n",
    "    valid_token = r.status_code == 200\n",
    "    if not(valid_token): print(r.status_code, type(r.status_code))\n",
    "    return valid_token\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def create_job(self: Salesforce, \n",
    "                sf_object: str ='Contact', # the Salesforce object were going to operate on. \n",
    "                operation: str ='insert', # the database operation to use. Can be \"insert\",\"upsert\" or \"delete\"\n",
    "                external_id: str = 'External_Id__c' # when using \"upsert\", this field is used to identify the record\n",
    "                )-> requests.Response :\n",
    "    \"\"\"Get job_id from Salesforce Bulk API\n",
    "\n",
    "    \"\"\"\n",
    "    # Args: \n",
    "    #     sf_object (str, optional): the Salesforce object were going to operate on. Defaults to 'Contact'.\n",
    "    #     operation (str, optional): âˆ†. Defaults to 'insert'.\n",
    "    #     external_id (str, optional): the external id field for upsert operations. Defaults to 'External_Id__c'.\n",
    "    #     sf_object (str, optional): the Salesforce object were going to operate on. Defaults to 'Contact'.\n",
    "    #     operation (str, optional): the operation that will be used against the object. Defaults to 'insert'.\n",
    "    #     external_id (str, optional): the external id field for upsert operations. Defaults to 'External_Id__c'.\n",
    "    #     contentType (str, optional): the content type of the file. Defaults to 'CSV', 'JSON' also accepted.\n",
    "    # Returns: \n",
    "    #     response: a response object containg the job_id. For more information on the response object see https://www.w3schools.com/python/ref_requests_response.asp\n",
    "    #     a response object see https://www.w3schools.com/python/ref_requests_response.asp\n",
    "        \n",
    "    # Salesforce API docs: https://developer.salesforce.com/docs/atlas.en-us.api_asynch.meta/api_asynch/create_job.htm    \n",
    "    \n",
    "    url = \"https://cremaconsulting-dev-ed.develop.my.salesforce.com/services/data/v57.0/jobs/ingest\"\n",
    "\n",
    "    # https://developer.salesforce.com/docs/atlas.en-us.api_asynch.meta/api_asynch/datafiles_prepare_csv.htm\n",
    "    ## we can set columnDelimiter to `,^,|,;,<tab>, and the default <comma>\n",
    "    # sets the object to Contact, the content type to CSV, and the operation to insert\n",
    "    payload_d = {\n",
    "        \"object\": sf_object,\n",
    "        \"contentType\": \"CSV\",\n",
    "        # set columnDelimiter to TAB instead of comma for ease of dealing with commas in address fields\n",
    "        #https://developer.salesforce.com/docs/atlas.en-us.api_asynch.meta/api_asynch/create_job.htm\n",
    "        \"columnDelimiter\": \"TAB\", \n",
    "        \"operation\": operation\n",
    "    }\n",
    "    \n",
    "    # as per https://developer.salesforce.com/docs/atlas.en-us.api_asynch.meta/api_asynch/walkthrough_upsert.htm\n",
    "    if operation=='upsert':\n",
    "        payload_d['externalIdFieldName']=external_id\n",
    "    print(operation, payload_d)        \n",
    "    payload = json.dumps(payload_d)\n",
    "    \n",
    "    headers = {\n",
    "    'Content-Type': 'application/json',\n",
    "    'Authorization': f'Bearer {self.sf_access_token}'\n",
    "    }\n",
    "\n",
    "    response = requests.request(\"POST\", url, headers=headers, data=payload)\n",
    "    print(response.text)\n",
    "    self.bulk_job_id = response.json()['id']\n",
    "    return response \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def upload_csv(self : Salesforce, \n",
    "                obj_s: str = \"\", # ATMS object to upload \n",
    "                num_rows: int = 100, # the number of rows to upload \n",
    "                ) -> requests.Response:\n",
    "    \"\"\"Using the job_id from the previous step, upload the csv file to the job\n",
    "\n",
    "    Args:\n",
    "        file (filepointer): file pointer to the csv filek\n",
    "    \"\"\"\n",
    "    # if not(file):\n",
    "    #     # throw error\n",
    "    #     assert False, \"File not found\"\n",
    "\n",
    "    if len(obj_s)==0: # no file path provided\n",
    "        assert False, \"obj_s must not be empty\"\n",
    "    if not(self.atms):\n",
    "        # throw error\n",
    "        assert False, \"Salesforce.atms must be assigned\"\n",
    "    \n",
    "            \n",
    "    file_path_s = os.path.join(self.atms.download_dir , f\"atms_transformed_{obj_s}.csv\")\n",
    "\n",
    "    url = f\"https://cremaconsulting-dev-ed.develop.my.salesforce.com/services/data/v57.0/jobs/ingest/{self.bulk_job_id}/batches\"\n",
    "\n",
    "    # replace all occurrences of '\\2019' with \\'\n",
    "    # we may have done this in ATMS already, but just in case\n",
    "    try:\n",
    "        for line in fileinput.input(files=file_path_s, inplace=True):\n",
    "            line = line.replace('\\u2019', \"'\")\n",
    "            print(line, end='')\n",
    "\n",
    "        _df : pd.Dataframe = pd.read_csv(file_path_s, sep='\\t')\n",
    "        payload : dict = _df[- num_rows:].to_dict()\n",
    "        # with open(file_path_s,'r') as payload:\n",
    "        headers = {\n",
    "        'Content-Type': 'text/csv',\n",
    "        'Authorization': f'Bearer {self.sf_access_token}'\n",
    "        }\n",
    "        response = requests.request(\"PUT\", url, headers=headers, data=payload)\n",
    "    except FileNotFoundError:\n",
    "        print(\"File not found: \", file_path_s)\n",
    "        return None\n",
    "    \n",
    "    return response\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "@patch\n",
    "def close_job(self: Salesforce):\n",
    "    # close the job (from Postman)\n",
    "    url = f\"https://cremaconsulting-dev-ed.develop.my.salesforce.com/services/data/v57.0/jobs/ingest/{self.bulk_job_id}\"\n",
    "\n",
    "    payload = json.dumps({\n",
    "        \"state\": \"UploadComplete\"\n",
    "    })\n",
    "    headers = {\n",
    "    'Content-Type': 'application/json',\n",
    "    'Authorization': f'Bearer {self.sf_access_token}'\n",
    "    }\n",
    "\n",
    "    response = requests.request(\"PATCH\", url, headers=headers, data=payload)\n",
    "\n",
    "    print(response.text)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export       \n",
    "# get job status (from Postman)\n",
    "@patch\n",
    "def job_status(self: Salesforce):\n",
    "    url = f\"https://cremaconsulting-dev-ed.develop.my.salesforce.com/services/data/v57.0/jobs/ingest/{self.bulk_job_id}\"\n",
    "\n",
    "    payload = {}\n",
    "    headers = {\n",
    "    'Authorization': f'Bearer {self.sf_access_token}'\n",
    "    }\n",
    "    response = requests.request(\"GET\", url, headers=headers, data=payload)\n",
    "    return response.json()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def successful_results(self : Salesforce):\n",
    "    url = f\"https://cremaconsulting-dev-ed.develop.my.salesforce.com/services/data/v57.0/jobs/ingest/{self.bulk_job_id}/successfulResults\"\n",
    "\n",
    "    payload = {}\n",
    "    headers = {\n",
    "        'Authorization': f'Bearer {self.sf_access_token}'\n",
    "    }\n",
    "\n",
    "    response = requests.request(\"GET\", url, headers=headers, data=payload)\n",
    "    print( response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def failed_results(self: Salesforce):\n",
    "    url = f\"https://cremaconsulting-dev-ed.develop.my.salesforce.com/services/data/v57.0/jobs/ingest/{self.bulk_job_id}/failedResults\"\n",
    "\n",
    "    payload = {}\n",
    "    headers = {\n",
    "        'Authorization': f'Bearer {self.sf_access_token}'\n",
    "    }\n",
    "\n",
    "    response = requests.request(\"GET\", url, headers=headers, data=payload)\n",
    "\n",
    "    print( response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def get_sf_object_ids(self: Salesforce, \n",
    "                      object: str = 'Contact' # REST endpoint for data object\n",
    "                      ):\n",
    "    \"\"\"Get Safesforce IDs for a the specified object\n",
    "\n",
    "    \"\"\"\n",
    "    print(f\"Retrieving Object Ids for {object} from Salesforce\")\n",
    "    sf_headers = { 'Authorization': f\"Bearer {self.sf_access_token}\", 'Content-Type': 'application/json' }\n",
    "    end_point =\"https://cremaconsulting-dev-ed.develop.my.salesforce.com\"\n",
    "    service = \"/services/data/v57.0/\"\n",
    "    r = requests.request(\"GET\", end_point+service+f\"query/?q=SELECT+Id+FROM+{object}\", headers=sf_headers, data={})\n",
    "    assert isinstance(r.json(), dict), f\"response: {r.json()}, header: {sf_headers}\"\n",
    "    object_ids = [d.get('Id') for d in r.json()['records']]\n",
    "    while r.json()['done'] == False:\n",
    "        new_url = end_point+r.json()['nextRecordsUrl']\n",
    "        print(new_url)\n",
    "        r = requests.request(\"GET\", new_url, headers=sf_headers, data={})\n",
    "        print((r.json()))\n",
    "        fresh_object_ids = [d.get('Id') for d in r.json()['records']]\n",
    "        print(len(fresh_object_ids))   \n",
    "        object_ids+=fresh_object_ids\n",
    "        \n",
    "    print('total number of objects = ',len(object_ids))\n",
    "    return object_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def delete_sf_objects(self: Salesforce, \n",
    "                      obj_s: str = 'Contact'\n",
    "                      ):\n",
    "    object_ids = self.get_sf_object_ids(obj_s)\n",
    "    with open('objs2delete.csv', 'w') as f:\n",
    "        f.write('Id\\n')\n",
    "        for id in object_ids:\n",
    "            f.write(id+'\\n')\n",
    "    job_id = self.create_job( obj_s, 'delete').json()['id']\n",
    "    print(\"Job id is: \", job_id)\n",
    "    self.upload_csv('objs2delete.csv')\n",
    "    sleep(2)\n",
    "    self.close_job()\n",
    "    sleep(10)\n",
    "    self.successful_results()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def test_sf_object_load_and_delete(self: Salesforce, \n",
    "        sf_object_s : str = None, # Salesforce API endpoint\n",
    "        input_file_s: str = None, # local file name\n",
    "        remove_sf_objs: bool = False # remove the data just added to Salesforce\n",
    "        ):\n",
    "    \"\"\"Test loading a Salesforce object with data from a local file\"\"\"\n",
    "    assert sf_object_s\n",
    "    assert input_file_s\n",
    "\n",
    "    # sf.create_job('MembershipMembers__c', contentType='CSV')\n",
    "    self.create_job(sf_object_s, contentType='CSV')\n",
    "    print(\"Salesforce job id: \", self.bulk_job_id)\n",
    "\n",
    "    #replace \n",
    "    # culprit is \\u2019 - it cannot be encoded in latin-1 codec\n",
    "    self.upload_csv(input_file_s)\n",
    "    \n",
    "        \n",
    "\n",
    "    self.close_job()\n",
    "    self.failed_results()\n",
    "    self.successful_results()\n",
    "    self.job_status()\n",
    "\n",
    "    if remove_sf_objs:\n",
    "        self.delete_sf_objects('membershipTerm__c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "\n",
    "mem_s = \"[].{membershipId__c: membershipId, \\\n",
    "    memberSince__c: memberSince, \\\n",
    "    updateDate__c: updateDate}\"\n",
    "\n",
    "memTerm_s = \"[:50].membershipTerms[].{membershipTermId__c: membershipTermId,\\\n",
    "membershipKey__r_1_membershipId__c:membershipKey,\\\n",
    "effectiveDate__c:effectiveDate,\\\n",
    "expiryDate__c:expiryDate,\\\n",
    "membershipType__c:membershipType,\\\n",
    "upgradeFromTermKey__c:upgradeFromTermKey,\\\n",
    "giftMembership__c:giftMembership,\\\n",
    "refunded__c:refunded,\\\n",
    "saleDetailKey__c:saleDetailKey,\\\n",
    "itemKey__c:itemKey}\"\n",
    "\n",
    "memMembers_s = \"[].membershipTerms[].membershipMembers[].{membershipMemberId__c:membershipMemberId,\\\n",
    "membershipTermKey__r_1_membershipTermId__c:membershipTermKey,\\\n",
    "cardNumber__c:cardNumber,\\\n",
    "membershipNumber__c:membershipNumber,\\\n",
    "cardStatus__c:cardStatus,\\\n",
    "contactKey__c:contactKey,\\\n",
    "displayName__c:displayName}\"\n",
    "\n",
    "@patch\n",
    "def process_memberships(self: Salesforce ):\n",
    "    \"\"\"Unpack memberships data from atms object and write to membership, membership_terms, and membership_members csv files.\"\"\"\n",
    "\n",
    "    mem_d = { 'memberships': {'fname':'membership.csv', 'jmespath': mem_s},\n",
    "               'membership_terms': {'fname':'membership_terms.csv','jmespath': memTerm_s},\n",
    "               'membership_members': {'fname': 'membership_members.csv', 'jmespath': memMembers_s}\n",
    "                }\n",
    "            \n",
    "\n",
    "    if not ('memberships' in self.atms.obj_d):\n",
    "        self.atms.load_data_file_to_dict('memberships')\n",
    "        assert 'memberships' in self.atms.obj_d, f\"memberships not in atms.obj_d {self.atms.obj_d.keys()}\"\n",
    "    \n",
    "    atms_d = self.atms.obj_d['memberships']\n",
    "\n",
    "    for key, v_pair in mem_d.items():\n",
    "        file_path_s = os.path.join(Salesforce.class_download_dir, v_pair['fname'])\n",
    "        dict_l = jp.search(v_pair['jmespath'], atms_d)\n",
    "        with open(file_path_s, 'w') as f:\n",
    "            # hack to create header with a dot in it, jmespath won't do it\n",
    "            f.write('\\t'.join([s.replace('_1_','.') for s in dict_l[0].keys()]) + '\\n') # header\n",
    "            for d in dict_l:\n",
    "                #changed this to not write None for empty values, eg \"\" for null and false (a default value)\n",
    "                f.write('\\t'.join([str(v) if v else \"\" for v in d.values()]) + '\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "search_s = \"[].{LastName: organizationName,\\\n",
    "    MailingPostalCode: addresses[0].postalZipCode,\\\n",
    "    MailingCity: addresses[0].city,\\\n",
    "    MailingStreet: addresses[0].line1, \\\n",
    "    MailingCountry: addresses[0].country, \\\n",
    "    Phone: phones[?phoneType == 'Business'].phoneNumber | [0],\\\n",
    "    Email: emails[0].address[0],\\\n",
    "    External_Id__c: contactId}\"\n",
    "\n",
    "import re\n",
    "\n",
    "def escape_quotes(text):\n",
    "    # Escape single quotes\n",
    "    # text = re.sub(r\"\\'\", r\"\\\\'\", text)\n",
    "    text = re.sub(r\"\\'\", r\"_\", text)\n",
    "    # Escape double quotes\n",
    "    text = re.sub(r'\\\"', r'_', text)\n",
    "    # text = re.sub(r',', r'*', text) ## shouldn't be necessary with tab delimiter\n",
    "    # text = re.sub(r'\\\"', r'\\\\\"', text)\n",
    "    return text.strip()\n",
    "\n",
    "@patch\n",
    "def process_contacts(self: Salesforce ):\n",
    "    \"\"\" unpack contacts data from atms object and write to contacts csv file.\"\"\"\n",
    "    if not ('contacts' in self.atms.obj_d):\n",
    "        self.atms.load_data_file_to_dict('contacts')\n",
    "        assert 'contacts' in self.atms.obj_d, f\"contacts not in atms.obj_d {self.atms.obj_d.keys()}\"\n",
    "    \n",
    "    file_path_s = os.path.join(Salesforce.class_download_dir, 'contacts.csv')\n",
    "    dict_l = jp.search(search_s, self.atms.obj_d['contacts'])\n",
    "\n",
    "    columnDelimiter = '\\t'\n",
    "    with open(file_path_s, 'w') as f:\n",
    "        header = columnDelimiter.join(dict_l[0].keys())\n",
    "        f.write(header+'\\n')\n",
    "        for item in dict_l:\n",
    "            l = [escape_quotes(str(v)) if v else \" \" for v in item.values()]\n",
    "            f.write(columnDelimiter.join(l)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory 'atms_download' already exists.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'00D8Y000001RMKv!AQwAQL0IbKf.zyFX.rpTa9VYNWx38N_Z9.mXsVyOZoU6ycdKW4_2o4HctbhjBNYwZ9LQV93zz1cC1kE.hFdhxOQWQODVQ8vI'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sf = Salesforce()\n",
    "sf._sf_access_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory 'atms_download' already exists.\n",
      "my id is b5pwwcmw\n",
      "download dir is:  /Users/josephmann/Documents/Github/doubledot/atms_download/b5pwwcmw\n",
      "resp_d = self.get_telus_data(memberships,offset=0, count= 1000, since_date=)\n",
      "resp_d = self.get_telus_data(memberships,offset=1000, count= 1000, since_date=)\n",
      "cleaning_data_file - download dir is:  /Users/josephmann/Documents/Github/doubledot/atms_download/b5pwwcmw\n",
      "creating file:  /Users/josephmann/Documents/Github/doubledot/atms_download/b5pwwcmw/atms_transformed_memberships.json\n",
      "Finished cleaning atms_memberships.json -> /Users/josephmann/Documents/Github/doubledot/atms_download/b5pwwcmw/atms_transformed_memberships.json\n",
      "Attempting to load:  /Users/josephmann/Documents/Github/doubledot/atms_download/b5pwwcmw/atms_transformed_memberships.json\n"
     ]
    }
   ],
   "source": [
    "atms = ATMS_api()\n",
    "atms.retrieve_and_clean('memberships')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf.atms = atms\n",
    "sf.process_memberships()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vantix",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
